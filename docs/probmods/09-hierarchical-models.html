<!DOCTYPE html>
<html>
<head>
  <title>ProbMods: Hierarchical Models</title>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js" onload="renderMathInElement(document.body,{delimiters:[{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}]})"></script>
  <script src="../js/editor.js"></script>
  <script src="../js/physics.js"></script>
  <script>ProbPhysics.setup();</script>
  <script src="https://cdn.jsdelivr.net/npm/scittle@0.7.28/dist/scittle.js" crossorigin="anonymous"></script>
</head>
<body>
<div id="chapter-wrapper">
  <div id="header">
    <div id="logotype"><a href="index.html">Probabilistic Models of Cognition</a></div>
    <ul id="nav">
      <li><a href="08-learning-as-conditional-inference.html">&larr; Prev</a></li>
      <li><a href="index.html">Index</a></li>
    </ul>
  </div>
  <div id="chapter">


<h1 id="chapter-title">9. Hierarchical Models</h1>

<div class="toc">
<div class="name">Contents:</div>
<ul>
<li><a href="#learning-a-shared-prototype">Learning a Shared Prototype: Abstraction at the Basic Level</a></li>
<li><a href="#the-blessing-of-abstraction">The Blessing of Abstraction</a></li>
<li><a href="#learning-overhypotheses">Learning Overhypotheses: Abstraction at the Superordinate Level</a></li>
<li><a href="#example-the-shape-bias">Example: The Shape Bias</a></li>
<li><a href="#example-beliefs-about-homogeneity">Example: Beliefs about Homogeneity and Generalization</a></li>
<li><a href="#example-one-shot-learning">Example: One-shot Learning of Visual Categories</a></li>
<li><a href="#example-x-bar-theory">Example: X-Bar Theory</a></li>
<li><a href="#thoughts-on-hierarchical-models">Thoughts on Hierarchical Models</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>


<p>Human knowledge is organized hierarchically into levels of abstraction. For instance, the most common or <em>basic-level</em> categories (e.g. <em>dog</em>, <em>car</em>) can be thought of as abstractions across individuals, or more often across subordinate categories (e.g., <em>poodle</em>, <em>Dalmatian</em>, <em>Labrador</em>, and so on). Multiple basic-level categories in turn can be organized under superordinate categories: e.g., <em>dog</em>, <em>cat</em>, <em>horse</em> are all <em>animals</em>; <em>car</em>, <em>truck</em>, <em>bus</em> are all <em>vehicles</em>. Some of the deepest questions of cognitive development are: How does abstract knowledge influence learning of specific knowledge? How can abstract knowledge be learned? In this section we will see how such hierarchical knowledge can be modeled with <em>hierarchical generative models</em>: generative models with uncertainty at several levels, where lower levels depend on choices at higher levels.</p>


<h1 id="learning-a-shared-prototype"><a href="#learning-a-shared-prototype">Learning a Shared Prototype: Abstraction at the Basic Level</a></h1>

<p>Hierarchical models allow us to capture the shared latent structure underlying observations of multiple related concepts, processes, or systems&mdash;to abstract out the elements in common to the different sub-concepts, and to filter away uninteresting or irrelevant differences. Perhaps the most familiar example of this problem occurs in learning about categories. Consider a child learning about a basic-level kind, such as <em>dog</em> or <em>car</em>. Each of these kinds has a prototype or set of characteristic features, and our question here is simply how that prototype is acquired.</p>

<p>The task is challenging because real-world categories are not homogeneous. A basic-level category like <em>dog</em> or <em>car</em> actually spans many different subtypes: e.g., <em>poodle</em>, <em>Dalmatian</em>, <em>Labrador</em>, and such, or <em>sedan</em>, <em>coupe</em>, <em>convertible</em>, <em>wagon</em>, and so on. The child observes examples of these sub-kinds or <em>subordinate</em>-level categories: a few poodles, one Dalmatian, three Labradors, etc. From this data she must infer what it means to be a dog in general, in addition to what each of these different kinds of dog is like. Knowledge about the prototype level includes understanding what it means to be a prototypical dog and what it means to be non-prototypical, but still a dog. This will involve understanding that dogs come in different breeds which share features between them, but also differ systematically as well.</p>

<p>As a simplification of this situation consider the following generative process. We will draw marbles out of several different bags. There are five marble colors. Each bag has a certain &ldquo;prototypical&rdquo; mixture of colors. This generative process is represented in the following example using the Dirichlet distribution (the Dirichlet is the higher-dimensional analogue of the Beta distribution).</p>

<pre><code>(def colors ['black 'blue 'green 'orange 'red])

(def bag->prototype
  (mem (fn [bag] (dirichlet [1 1 1 1 1]))))

(defn draw-marbles [bag num-draws]
  (repeatedly num-draws
    (fn [] (multinomial colors (bag->prototype bag)))))

(hist (draw-marbles 'bag 50) "first sample")
(hist (draw-marbles 'bag 50) "second sample")
(hist (draw-marbles 'bag 50) "third sample")
(hist (draw-marbles 'bag 50) "fourth sample")</code></pre>

<p>Note that we are using the function <code>mem</code> that we introduced earlier. <code>mem</code> is particularly useful when writing hierarchical models because it allows us to associate arbitrary random draws with categories across entire runs of the program. In this case it allows us to associate a particular mixture of marble colors with each bag. The mixture is drawn once, and then remains the same thereafter for that bag.</p>

<p>Run the code above multiple times. Each run creates a single bag of marbles with its characteristic distribution of marble colors, and then draws four samples of 50 marbles each. Intuitively, you can see how each sample is sufficient to learn a lot about what that bag is like; there is typically a fair amount of similarity between the empirical color distributions in each of the four samples from a given bag. In contrast, you should see a lot more variation across different runs of the code&mdash;samples from different bags.</p>

<p>Now let&rsquo;s add a few twists: we will generate three different bags, and try to learn about their respective color prototypes by conditioning on observations. We represent the results of learning in terms of the <em>posterior predictive</em> distribution for each bag: a single hypothetical draw from the bag. We will also draw a sample from the posterior predictive distribution on a new bag, for which we have had no observations.</p>

<pre><code>(def colors ['black 'blue 'green 'orange 'red])

(def samples
  (mh-query 200 100
    (let [proto-1 (dirichlet [1 1 1 1 1])
          proto-2 (dirichlet [1 1 1 1 1])
          proto-3 (dirichlet [1 1 1 1 1])
          proto-n (dirichlet [1 1 1 1 1])]
      ;; condition on observations from three bags:
      (doseq [v ['blue 'blue 'black 'blue 'blue 'blue]]
        (observe (categorical-dist colors proto-1) v))
      (doseq [v ['blue 'green 'blue 'blue 'blue 'red]]
        (observe (categorical-dist colors proto-2) v))
      (doseq [v ['blue 'blue 'blue 'blue 'blue 'orange]]
        (observe (categorical-dist colors proto-3) v))
      ;; predict the next sample from each observed bag, and a new one:
      [(multinomial colors proto-1)
       (multinomial colors proto-2)
       (multinomial colors proto-3)
       (multinomial colors proto-n)])))

(hist (map #(nth % 0) samples) "bag one posterior predictive")
(hist (map #(nth % 1) samples) "bag two posterior predictive")
(hist (map #(nth % 2) samples) "bag three posterior predictive")
(hist (map #(nth % 3) samples) "bag n posterior predictive")</code></pre>

<p>This generative model describes the prototype mixtures in each bag, but it does not attempt to learn a common higher-order prototype. It is like learning separate prototypes for subordinate classes <em>poodle</em>, <em>Dalmatian</em>, and <em>Labrador</em>, without learning a prototype for the higher-level kind <em>dog</em>&mdash;or learning about any functions that are shared across the different lower-level classes or bags. Specifically, inference suggests that each bag is predominantly blue, but with a fair amount of residual uncertainty about what other colors might be seen. There is no information shared across bags, and nothing significant is learned about <code>bag-n</code> as it has no observations and no structure shared with the bags that have been observed.</p>

<p>Now let us introduce another level of abstraction: a global prototype that provides a prior on the specific prototype mixtures of each bag.</p>

<pre><code>(def colors ['black 'blue 'green 'orange 'red])

(def samples
  (mh-query 200 100
    (let [;; global prototype: a dirichlet sample scaled to total 5
          prototype (mapv #(* 5 %) (dirichlet [1 1 1 1 1]))
          ;; each bag's prototype uses the global one as parameters
          proto-1 (dirichlet prototype)
          proto-2 (dirichlet prototype)
          proto-3 (dirichlet prototype)
          proto-n (dirichlet prototype)]
      ;; condition on observations from three bags:
      (doseq [v ['blue 'blue 'black 'blue 'blue 'blue]]
        (observe (categorical-dist colors proto-1) v))
      (doseq [v ['blue 'green 'blue 'blue 'blue 'red]]
        (observe (categorical-dist colors proto-2) v))
      (doseq [v ['blue 'blue 'blue 'blue 'blue 'orange]]
        (observe (categorical-dist colors proto-3) v))
      [(multinomial colors proto-1)
       (multinomial colors proto-2)
       (multinomial colors proto-3)
       (multinomial colors proto-n)])))

(hist (map #(nth % 0) samples) "bag one posterior predictive")
(hist (map #(nth % 1) samples) "bag two posterior predictive")
(hist (map #(nth % 2) samples) "bag three posterior predictive")
(hist (map #(nth % 3) samples) "bag n posterior predictive")</code></pre>

<p>Compared with inferences in the previous example, this extra level of abstraction enables faster learning: more confidence in what each bag is like based on the same observed sample. This is because all of the observed samples suggest a common prototype structure, with most of its weight on <code>blue</code> and the rest of the weight spread uniformly among the remaining colors. Statisticians sometimes refer to this phenomenon of inference in hierarchical models as &ldquo;sharing of statistical strength&rdquo;: it is as if the sample we observe for each bag also provides a weaker indirect sample relevant to the other bags. In machine learning and cognitive science this phenomenon is often called <em>learning to learn</em> or <em>transfer learning.</em> Intuitively, knowing something about bags in general allows the learner to transfer knowledge gained from draws from one bag to other bags. This example is analogous to seeing several examples of different subtypes of dogs and learning what features are in common to the more abstract basic-level dog prototype, independent of the more idiosyncratic features of particular dog subtypes.</p>

<p>A particularly striking example of &ldquo;sharing statistical strength&rdquo; or &ldquo;learning to learn&rdquo; can be seen if we change the observed sample for bag 3 to have only two examples, one blue and one orange. Replace the observations for bag 3 with <code>['blue 'orange]</code> in each program above. In a situation where we have no shared higher-order prototype structure, inference for bag-3 from these observations suggests that <code>blue</code> and <code>orange</code> are equally likely. However, when we have inferred a shared higher-order prototype, then the inferences we make for bag 3 look much more like those we made before, with six observations (five blue, one orange), because the learned higher-order prototype tells us that blue is most likely to be highly represented in any bag regardless of which other colors (here, orange) may be seen with lower probability.</p>

<p>Learning about shared structure at a higher level of abstraction also supports inferences about new bags without observing <em>any</em> examples from that bag: a hypothetical new bag could produce any color, but is likely to have more blue marbles than any other color. We can imagine hypothetical, previously unseen, new subtypes of dogs that share the basic features of dogs with more familiar kinds but may differ in some idiosyncratic ways.</p>


<h1 id="the-blessing-of-abstraction"><a href="#the-blessing-of-abstraction">The Blessing of Abstraction</a></h1>

<p>Now let&rsquo;s investigate the relative learning speeds at different levels of abstraction. Suppose that we have a number of bags that all have identical prototypes: they mix red and blue in proportion 2:1. But the learner doesn&rsquo;t know this. She observes only one ball from each of N bags. What can she learn about an individual bag versus the population as a whole as the number of bags changes?</p>

<pre><code>(def colors ['red 'blue])

(defn sample-bags [obs-draws]
  (mh-query 80 30
    (let [phi (dirichlet [1 1])
          global-prototype (mapv #(* 2 %) phi)
          bag-names (mapv first obs-draws)
          protos (mapv (fn [_] (dirichlet global-prototype)) bag-names)
          bag->proto (zipmap bag-names protos)]
      ;; observe each bag's marbles
      (doseq [[bag &amp; values] obs-draws]
        (doseq [v values]
          (observe (categorical-dist colors (bag->proto bag)) v)))
      ;; return [bag1 prototype red-prob, global red-prob]
      [(first (bag->proto (first bag-names)))
       (first phi)])))

;; Mean squared error from true value:
(defn mean-dev [truth samps]
  (mean (map (fn [s] (expt (- truth s) 2)) samps)))

;; Baseline with no observations:
(def baseline (sample-bags [['bag1]]))
(def init-spec (max 0.001 (mean-dev 0.66 (map first baseline))))
(def init-gen  (max 0.001 (mean-dev 0.66 (map second baseline))))

;; One observation per bag (2:1 red:blue):
(def observations
  [['bag1 'red] ['bag2 'red] ['bag3 'blue]
   ['bag4 'red] ['bag5 'red] ['bag6 'blue]
   ['bag7 'red] ['bag8 'red] ['bag9 'blue]
   ['bag10 'red] ['bag11 'red] ['bag12 'blue]])
(def num-obs [1 3 6 9 12])

(def all-samples (mapv #(sample-bags (vec (take % observations))) num-obs))
(def mse-spec (mapv #(/ (mean-dev 0.66 (map first %)) init-spec) all-samples))
(def mse-gen  (mapv #(/ (mean-dev 0.66 (map second %)) init-gen) all-samples))

(lineplot
  [{:data (cons [0 1.0] (map vector num-obs mse-spec)) :label "specific"}
   {:data (cons [0 1.0] (map vector num-obs mse-gen))  :label "general"}]
  "Learning curves (normalized MSE)")</code></pre>

<p>We are plotting learning curves: the mean squared error of the prototype from the true prototype for the specific level (the first bag) and the general (global prototype) level as a function of the number of observed data points. What we see is that learning is faster at the general level than the specific level&mdash;that is that the error in the estimated prototype drops faster in the general than the specific plots. We also see that there is continued learning at the specific level, even though we see no additional samples from the first bag after the first; this is because the evolving knowledge at the general level further constrains the inferences at the specific level. Going back to our familiar categorization example, this suggests that a child could be quite confident in the prototype of &ldquo;dog&rdquo; while having little idea of the prototype for any specific kind of dog&mdash;learning more quickly at the abstract level than the specific level, but then using this abstract knowledge to constrain expectations about the specific level. This dynamic depends crucially on the fact that we get very diverse evidence: try changing the above example to observe the same N examples, but coming from a single bag (instead of N bags). You should now see that learning for this bag is quick, while global learning (and transfer) is slow.</p>

<p>In machine learning one often talks of the <em>curse of dimensionality</em>. The curse of dimensionality refers to the fact that as the number of parameters of a model increases (i.e. the dimensionality of the model increases), the size of the hypothesis space increases exponentially. This increase in the size of the hypothesis space leads to two related problems. The first is that the amount of data required to estimate model parameters (called the &ldquo;sample complexity&rdquo;) increases rapidly as the dimensionality of the hypothesis space increases. The second is that the amount of computational work needed to search the hypothesis space also rapidly increases. Thus, increasing model complexity by adding parameters can result in serious problems for inference.</p>

<p>In contrast, we have seen that adding additional levels of abstraction (and hence additional parameters) in a probabilistic model can sometimes make it possible to learn <em>more</em> with <em>fewer</em> observations. This happens because learning at the abstract level can be quicker than learning at the specific level. Because this ameliorates the curse of dimensionality, we refer to these effects as the <strong>blessing of abstraction</strong>.</p>

<p>In general, the blessing of abstraction can be surprising because our intuitions often suggest that adding more hierarchical levels to a model increases the model&rsquo;s complexity. More complex models should make learning harder, rather than easier. On the other hand, it has long been understood in cognitive science that learning is made easier by the addition of <em>constraints</em> on possible hypotheses. For instance, proponents of universal grammar have long argued for a highly constrained linguistic system on the basis of learnability. Their theories often have an explicitly hierarchical flavor. Hierarchical Bayesian models can be seen as a way of introducing soft, probabilistic constraints on hypotheses that allow for the transfer of knowledge between different kinds of observations.</p>


<h1 id="learning-overhypotheses"><a href="#learning-overhypotheses">Learning Overhypotheses: Abstraction at the Superordinate Level</a></h1>

<p>Hierarchical models also allow us to capture a more abstract and even more important &ldquo;learning to learn&rdquo; phenomenon, sometimes called learning <em>overhypotheses</em>. Consider how a child learns about living creatures (an example we adapt from the psychologists Liz Shipley and Rob Goldstone). We learn about specific kinds of animals&mdash;dogs, cats, horses, and more exotic creatures like elephants, ants, spiders, sparrows, eagles, dolphins, goldfish, snakes, worms, centipedes&mdash;from examples of each kind. These examples tell us what each kind is like: Dogs bark, have four legs, a tail. Cats meow, have four legs and a tail. Horses neigh, have four legs and a tail. Ants make no sound, have six legs, no tail. Robins and eagles both have two legs, wings, and a tail; robins sing while eagles cry. Dolphins have fins, a tail, and no legs; likewise for goldfish. Centipedes have a hundred legs, no tail and make no sound. And so on. Each of these generalizations or prototypes may be inferred from seeing several examples of the species.</p>

<p>But we also learn about what kinds of creatures are like <em>in general</em>. It seems that certain kinds of properties of animals are characteristic of a particular kind: either every individual of a kind has this property, or none of them have it. Characteristic properties include number of legs, having a tail or not, and making some kind of sound. If one individual in a species has four legs, or six or two or eight or a hundred legs, essentially all individuals in that species have that same number of legs (barring injury, birth defect or some other catastrophe). Other kinds of properties don&rsquo;t pattern in such a characteristic way. Consider external color. Some kinds of animals are homogeneous in coloration, such as dolphins, elephants, sparrows. Others are quite heterogeneous in coloration: dogs, cats, goldfish, snakes. Still others are intermediate, with one or a few typical color patterns: horses, ants, eagles, worms.</p>

<p>This abstract knowledge about what animal kinds are like can be extremely useful in learning about new kinds of animals. Just one example of a new kind may suffice to infer the prototype or characteristic features of that kind: seeing a spider for the first time, and observing that it has eight legs, no tail and makes no sound, it is a good bet that other spiders will also have eight legs, no tail and make no sound. The specific coloration of the spider, however, is not necessarily going to generalize to other spiders. Although a basic statistics class might tell you that only by seeing many instances of a kind can we learn with confidence what features are constant or variable across that kind, both intuitively and empirically in children&rsquo;s cognitive development it seems that this &ldquo;one-shot learning&rdquo; is more the norm. How can this work? Hierarchical models show us how to formalize the abstract knowledge that enables one-shot learning, and the means by which that abstract knowledge is itself acquired (Kemp, Perfors, &amp; Tenenbaum, 2007).</p>

<p>We can study a simple version of this phenomenon by modifying our bags of marbles example, articulating more structure to the hierarchical model as follows. We now have two higher-level parameters: <code>phi</code> describes the expected proportions of marble colors across bags of marbles, while <code>alpha</code>, a real number, describes the strength of the learned prior&mdash;how strongly we expect any newly encountered bag to conform to the distribution for the population prototype <code>phi</code>. For instance, suppose that we observe that <code>bag-1</code> consists of all blue marbles, <code>bag-2</code> consists of all green marbles, <code>bag-3</code> all red, and so on. This doesn&rsquo;t tell us to expect a particular color in future bags, but it does suggest that bags are very regular&mdash;that all bags consist of marbles of only one color.</p>

<pre><code>(def colors ['black 'blue 'green 'orange 'red])

(def samples
  (mh-query 200 100
    (let [phi (dirichlet [1 1 1 1 1])
          alpha (gamma 2 2)
          prototype (mapv (fn [w] (* alpha w)) phi)
          proto-1 (dirichlet prototype)
          proto-2 (dirichlet prototype)
          proto-3 (dirichlet prototype)
          proto-4 (dirichlet prototype)
          proto-n (dirichlet prototype)]
      ;; observe bags of uniform color:
      (doseq [v ['blue 'blue 'blue 'blue 'blue 'blue]]
        (observe (categorical-dist colors proto-1) v))
      (doseq [v ['green 'green 'green 'green 'green 'green]]
        (observe (categorical-dist colors proto-2) v))
      (doseq [v ['red 'red 'red 'red 'red 'red]]
        (observe (categorical-dist colors proto-3) v))
      (doseq [v ['orange]]
        (observe (categorical-dist colors proto-4) v))
      [(multinomial colors proto-1)
       (multinomial colors proto-2)
       (multinomial colors proto-3)
       (multinomial colors proto-4)
       (multinomial colors proto-n)
       (js/Math.log alpha)])))

(hist (map #(nth % 0) samples) "bag one posterior predictive")
(hist (map #(nth % 1) samples) "bag two posterior predictive")
(hist (map #(nth % 2) samples) "bag three posterior predictive")
(hist (map #(nth % 3) samples) "bag four posterior predictive")
(hist (map #(nth % 4) samples) "bag n posterior predictive")
(density (map #(nth % 5) samples) "consistency across bags (log alpha)")</code></pre>

<p>This model uses the <em>gamma distribution</em> as a prior on the regularity parameter. Gamma is a useful continuous distribution on the non-negative numbers; with parameters \(\alpha = 2, \beta = 2\) it gives moderate prior weight to values around 1&ndash;3.</p>

<p>We have queried on the mixture of colors in a fourth bag, for which only one marble has been observed (orange), and we see a very strong posterior predictive distribution focused on orange&mdash;a &ldquo;one-shot&rdquo; generalization. This posterior is much stronger than the single observation for that bag can justify on its own. Instead, it reflects the learned overhypothesis that bags tend to be uniform in color.</p>

<p>To see that this is real one-shot learning, contrast with the predictive distribution for bag-n, where we have made no observations: <code>bag-n</code> gives a mostly flat distribution. Little has been learned in the hierarchical model about the specific colors represented in the overall population; rather we have learned the abstract property that bags of marbles tend to be uniform in color. Hence, a single observation from a new bag is enough to make strong predictions about that bag even though little could be said prior to seeing the first observation.</p>

<p>The above code shows a density plot of the inferred values of <code>alpha</code> (actually, its log value), representing how strongly the prototype distribution captured in <code>phi</code> constrains each individual bag&mdash;how much each individual bag is expected to look like the prototype of the population. You should see that the inferred values of <code>alpha</code> are typically significantly less than 1 (or log less than 0). This means roughly that the learned prototype in <code>phi</code> should exert less influence on prototype estimation for a new bag than a single observation. Hence the first observation we make for a new bag mostly determines a strong inference about what that bag is like.</p>

<p>Now change the observation data in the above code example as follows:</p>

<pre class="norun"><code>;; Replace the observe blocks with:
(doseq [v ['blue 'red 'green 'black 'red 'blue]]
  (observe (categorical-dist colors proto-1) v))
(doseq [v ['green 'red 'black 'black 'blue 'green]]
  (observe (categorical-dist colors proto-2) v))
(doseq [v ['red 'green 'blue 'blue 'black 'green]]
  (observe (categorical-dist colors proto-3) v))
(doseq [v ['orange]]
  (observe (categorical-dist colors proto-4) v))</code></pre>

<p>Intuitively, the observations for bags one, two and three should now suggest a very different overhypothesis: that marble color, instead of being homogeneous within bags but variable across bags, is instead variable within bags to about the same degree that it varies in the population as a whole. We can see this inference represented via two coupled effects. First, the inferred value of <code>alpha</code> is now significantly <em>greater</em> than 1 (log value greater than 0), asserting that the population distribution as a whole, <code>phi</code>, now exerts a strong constraint on what any individual bag looks like. Second, for a new <code>bag-4</code> which has been observed only once, with a single orange marble, that draw is now no longer very influential on the color distribution we expect to see from that bag; the broad distribution in <code>phi</code> exerts a much stronger influence than the single observation.</p>


<h1 id="example-the-shape-bias"><a href="#example-the-shape-bias">Example: The Shape Bias</a></h1>

<p>One well studied overhypothesis in cognitive development is the &ldquo;shape bias&rdquo;: the inductive bias which develops by 24 months and which is the preference to generalize a novel label for some object to other objects of the same shape, rather than say the same color or texture. Studies by Smith and colleagues (2002) have shown that this bias can be learned with very little data. They trained 17 month old children, over eight weeks, on four pairs of novel objects where the objects in each pair had the same shape but differed in color and texture and were consistently given the same novel name. First order generalization was tested by showing children an object from one of the four trained categories and asking them to choose another such object from three choice objects that matched the shown object in exactly one feature. Children preferred the shape match. Second order generalization was also tested by showing children an object from a novel category and again children preferred the choice object which matched in shape. Smith and colleagues further found an increase in real-world vocabulary as a result of this training such that children who had been trained began to use more object names. Children had thus presumably learned something like &ldquo;shape is homogeneous within object categories&rdquo; and were able to apply this inductive bias to word learning outside the lab.</p>

<p>We now consider a model of learning the shape bias which uses the compound Dirichlet-multinomial model that we have been discussing in the context of bags of marbles. This model for the shape bias is from Kemp et al. (2007). Rather than bags of marbles we now have object categories and rather than observing marbles we now observe the features of an object (e.g. its shape, color, and texture) drawn from one of the object categories. Suppose that a feature from each dimension of an object is generated independently of the other dimensions and there are separate values of alpha and phi for each dimension. Importantly, one needs to allow for more values along each dimension than appear in the training data so as to be able to generalize to novel shapes, colors, etc. To test the model we can feed it training data to allow it to learn the values for the alphas and phis corresponding to each dimension. We can then give it a single instance of some new category and then ask what the probability is that the various choice objects also come from the same new category.</p>

<pre><code>(def shapes (iota 11))
(def colors-dim (iota 11))
(def textures (iota 11))
(def sizes (iota 11))

(def samples
  (mh-query 100 100
    (let [;; global phis for each dimension:
          phi-shapes (dirichlet (make-list 11 1))
          phi-colors (dirichlet (make-list 11 1))
          phi-textures (dirichlet (make-list 11 1))
          phi-sizes (dirichlet (make-list 11 1))
          ;; regularity parameters per dimension:
          alpha-shapes (exponential 1)
          alpha-colors (exponential 1)
          alpha-textures (exponential 1)
          alpha-sizes (exponential 1)
          ;; global prototypes:
          proto-shapes (mapv #(* alpha-shapes %) phi-shapes)
          proto-colors (mapv #(* alpha-colors %) phi-colors)
          proto-textures (mapv #(* alpha-textures %) phi-textures)
          proto-sizes (mapv #(* alpha-sizes %) phi-sizes)
          dims [shapes colors-dim textures sizes]
          global-protos [proto-shapes proto-colors proto-textures proto-sizes]
          ;; category-specific prototypes (one set of 4 per category):
          make-cat-proto (fn [] (mapv dirichlet global-protos))
          cp1 (make-cat-proto) cp2 (make-cat-proto)
          cp3 (make-cat-proto) cp4 (make-cat-proto) cp5 (make-cat-proto)
          cat-protos {'cat-1 cp1 'cat-2 cp2 'cat-3 cp3 'cat-4 cp4 'cat-5 cp5}]
      ;; observe training data:
      (doseq [[cat observations]
              [['cat-1 [[1 1 1 1] [1 2 2 2]]]
               ['cat-2 [[2 3 3 1] [2 4 4 2]]]
               ['cat-3 [[3 5 5 1] [3 6 6 2]]]
               ['cat-4 [[4 7 7 1] [4 8 8 2]]]
               ['cat-5 [[5 9 9 1]]]]]
        (doseq [obj observations]
          (doseq [i (range 4)]
            (observe (categorical-dist (nth dims i) (nth (cat-protos cat) i))
                     (nth obj i)))))
      ;; predict shape of new object from cat-5:
      (multinomial shapes (first cp5)))))

(hist samples "Shape of object drawn from cat-5")</code></pre>

<p>The program above gives us draws from some novel category for which we&rsquo;ve seen a single instance. In the experiments with children, they had to choose one of three choice objects which varied according to the dimension they matched the example object from the category. The model predictions reproduce the general pattern of the experimental results of Smith et al in that shape matches are preferred in both the first and second order generalization case, and more strongly in the first order generalization case. The model also helps to explain the children&rsquo;s vocabulary growth in that it shows how the shape bias can be generally learned, as seen by the differing values learned for the various alpha parameters, and so used outside the lab.</p>

<p>The model can be extended to learn to apply the shape bias only to the relevant ontological kinds, for example to object categories but not to substance categories. The Kemp et al. (2007) paper discusses such an extension to the model which learns the hyperparameters separately for each kind and further learns what categories belong to each kind and how many kinds there are. This involves the use of a non-parametric prior, called the Chinese Restaurant Process, which will be discussed in a later chapter on non-parametric models.</p>


<h1 id="example-beliefs-about-homogeneity"><a href="#example-beliefs-about-homogeneity">Example: Beliefs about Homogeneity and Generalization</a></h1>

<p>In a 1983 paper, Nisbett and colleagues examined how, and under what conditions, people made use of statistical heuristics when reasoning. One question they considered was how and when people generalized from a few instances. They showed that to what extent people generalize depends on beliefs about the homogeneity of the group that the object falls in with respect to the property they are being asked to generalize about. In one study, they asked subjects the following question:</p>

<blockquote>
<p><em>Imagine that you are an explorer who has landed on a little known island in the Southeastern Pacific. You encounter several new animals, people, and objects. You observe the properties of your &ldquo;samples&rdquo; and you need to make guesses about how common these properties would be in other animals, people, or objects of the same type.</em></p>
</blockquote>

<p>The number of encountered instances of an object were varied (one, three, or twenty instances) as well as the type and property of the objects. For example:</p>

<blockquote>
<p><em>Suppose you encounter a native, who is a member of a tribe he calls the Barratos. He is obese. What percent of the male Barratos do you expect to be obese?</em></p>
</blockquote>

<blockquote>
<p>and</p>
</blockquote>

<blockquote>
<p><em>Suppose the Barratos man is brown in color. What percent of male Barratos do you expect to be brown (as opposed to red, yellow, black or white)?</em></p>
</blockquote>

<p>Results accord both with the beliefs of the experimenters about how heterogeneous different groups would be, and subjects&rsquo; stated reasons for generalizing in the way they did for the different instances (which were coded for beliefs about how homogeneous objects are with respect to some property).</p>

<p>Again, we can use the compound Dirichlet-multinomial model we have been working with throughout to model this task, following Kemp et al. (2007). In the context of the question about members of the Barratos tribe, replace bags of marbles with tribes and the color of marbles with skin color, or the property of being obese. Observing data such that skin color is consistent within tribes but varies between tribes will cause a low value of the alpha corresponding to skin color to be learned, and so seeing a single example from some new tribe will result in a sharply peaked predictive posterior distribution for the new tribe. Conversely, given data that obesity varies within a tribe the model will learn a higher value of the alpha corresponding to obesity and so will not generalize nearly as much from a single instance from a new tribe.</p>

<p>So far, we&rsquo;ve been using the compound Dirichlet-multinomial to do one-shot learning, by learning low values for the alpha hyperparameter. While such a Dirichlet distribution can lead to one-shot learning, we&rsquo;re not explicitly learning about the variance of the categories in the model. We might imagine a similar model in which we handle continuous quantities and directly represent hyperparameters for the mean and variance of various related groups.</p>

<pre><code>(def results
  (mh-query 50 500
    (let [overall-sd (gamma 1 1)
          group-shape (gamma 2 2)
          group-scale (gamma 2 2)
          sd-1 (gamma group-shape group-scale)
          sd-2 (gamma group-shape group-scale)
          sd-3 (gamma group-shape group-scale)
          sd-4 (gamma group-shape group-scale)
          sd-new (gamma group-shape group-scale)
          mean-1 (gaussian 1 overall-sd)
          mean-2 (gaussian 1 overall-sd)
          mean-3 (gaussian 1 overall-sd)
          mean-4 (gaussian 1 overall-sd)]
      ;; observe data from four groups:
      (doseq [v [1.001 1.001 1.001]]
        (observe (gaussian-dist mean-1 sd-1) v))
      (doseq [v [1.05 1.05 1.05]]
        (observe (gaussian-dist mean-2 sd-2) v))
      (doseq [v [1.1 1.1 1.1]]
        (observe (gaussian-dist mean-3 sd-3) v))
      (doseq [v [1.003]]
        (observe (gaussian-dist mean-4 sd-4) v))
      sd-new)))

(display (str "Inferred SD for a new group: " (mean results)))</code></pre>

<p>In the next section, we will discuss a more complicated example of &ldquo;learning to learn&rdquo; which also uses continuous distributions at the lowest level and learns something explicitly about the mean and covariance of both basic and superordinate categories.</p>


<h1 id="example-one-shot-learning"><a href="#example-one-shot-learning">Example: One-shot Learning of Visual Categories</a></h1>

<p>Humans are able to categorize objects (in a space with a huge number of dimensions) after seeing just one example of a new category. For example, after seeing a single wildebeest people are able to identify other wildebeest, perhaps by drawing on their knowledge of other animals. The model in Salakhutdinov et al. (2010) uses abstract knowledge learned from other categories as a prior on the mean and covariance matrix of new categories.</p>

<p>Suppose, first, that the model is given an assignment of objects to basic categories and basic categories to superordinate categories. Objects are represented as draws from a multivariate Gaussian and the mean and covariance of each basic category is determined by hyperparameters attached to the corresponding superordinate category. The parameters of the superordinate categories are all drawn from a common set of hyperparameters.</p>

<p>The model in the Salakhutdinov et al. (2010) paper is not actually given the assignment of objects to categories and basic categories to superordinate categories, but rather learns this from the data by putting a non-parametric prior over the tree of object and category assignments. Results show that this hierarchical approach enables significantly better one-shot retrieval performance compared to a simple Euclidean metric, demonstrating the power of learned abstract structure.</p>


<h1 id="example-x-bar-theory"><a href="#example-x-bar-theory">Example: X-Bar Theory</a></h1>

<p>(This example comes from an unpublished manuscript by O&rsquo;Donnell, Goodman, and Katzir)</p>

<p>One of the central problems in generative linguistics has been to account for the ease and rapidity with which children are able to acquire their language from noisy, incomplete, and sparse data. One suggestion for how this can happen is that the space of possible natural languages varies <em>parametrically</em>. The idea is that there are a number of higher-order constraints on structure that massively reduce the complexity of the learning problem. Each constraint is the result of a parameter taking on one of a small set of values. (This is known as &ldquo;principles and parameters&rdquo; theory.) The child needs only see enough data to set these parameters and the details of construction-specific structure will then generalize across the rest of the constructions of their language.</p>

<p>One example is the theory of headedness and X-bar phrase structure (see Chomsky, 1970; Jackendoff, 1981). X-bar theory provides a hierarchical model for phrase structure. All phrases follow the same basic <em>template</em>:</p>

\[ XP \longrightarrow Spec \ X^\prime \]
\[ X^\prime \longrightarrow X \ Comp \]

<p>Where \(X\) is a lexical (or functional) category such as \(N\) (noun), \(V\) (verb), etc. X-bar theory proposes that all phrase types have the same basic &ldquo;internal geometry&rdquo;; they have a <em>head</em>&mdash;a word of category \(X\). They also have a specifier (\(Spec\)) and a complement (\(Comp\)), the complement is more closely associated with the head than the specifier. The set of categories that can appear as complements and specifiers for a particular category of head is usually thought to be specified by universal grammar (but may also vary parametrically).</p>

<p>An important way in which languages vary is the order in which heads appear with respect to their complements (and specifiers). Within a language there tends to be a dominant order, often with exceptions for some category types. For instance, English is primarily a head-initial language. In verb phrases, for example, the direct object (complement noun phrase) of a verb appears to the right of the head. However, there are exceptional cases such as the order of (simple) adjective and nouns: adjectives appear before the noun rather than after it (although more complex complement types such as relative clauses appear after the noun).</p>

<p>The fact that languages show consistency in head directionality could be of great advantage to the learner; after encountering a relatively small number of phrase types and instances the learner of a consistent language can learn the dominant head direction in their language, transferring this knowledge to new phrase types. The fact that within many languages there are exceptions suggests that this generalization cannot be deterministic, however, and furthermore means that a learning approach will have to be robust to within-language variability. Here is a highly simplified model of X-Bar structure:</p>

<pre><code>(def data [['D 'N]])

;; a set of phrase categories, and the complement for each head:
(def categories ['D 'N 'T 'V 'A 'Adv])

(defn head->comp [head]
  (case head
    D 'N  T 'V  N 'A  V 'Adv  A 'none  Adv 'none  'error))

(def samples
  (mh-query 100 100
    (let [lang-dir (beta 1 1)
          dir-D   (first (dirichlet [lang-dir (- 1 lang-dir)]))
          dir-N   (first (dirichlet [lang-dir (- 1 lang-dir)]))
          dir-T   (first (dirichlet [lang-dir (- 1 lang-dir)]))
          dir-V   (first (dirichlet [lang-dir (- 1 lang-dir)]))
          dir-A   (first (dirichlet [lang-dir (- 1 lang-dir)]))
          dir-Adv (first (dirichlet [lang-dir (- 1 lang-dir)]))
          head->dir {'D dir-D 'N dir-N 'T dir-T 'V dir-V 'A dir-A 'Adv dir-Adv}
          gen-phrase (fn [head]
                       (if (= (head->comp head) 'none)
                         [head]
                         (if (flip (head->dir head))
                           [(head->comp head) head]
                           [head (head->comp head)])))]
      (condition (= data
                    (vec (repeatedly (count data)
                           #(gen-phrase (uniform-draw categories))))))
      (gen-phrase 'N))))

(hist samples "N-phrase headedness")</code></pre>

<p>First, try increasing the number of copies of <code>['D 'N]</code> in the data. What happens? Now, try changing the data to <code>[['D 'N] ['T 'V] ['V 'Adv]]</code>. What happens if you condition on additional instances of <code>['V 'Adv]</code>? How about <code>['Adv 'V]</code>?</p>

<p>What we see in this example is a simple probabilistic model capturing a version of the &ldquo;principles and parameters&rdquo; theory. Because it is probabilistic, systematic inferences will be drawn despite exceptional sentences or even phrase types. More importantly, due to the blessing of abstraction, the overall headedness of the language can be inferred from very little data&mdash;before the learner is very confident in the headedness of individual phrase types.</p>


<h1 id="thoughts-on-hierarchical-models"><a href="#thoughts-on-hierarchical-models">Thoughts on Hierarchical Models</a></h1>

<p>We have just seen several examples of <em>hierarchical Bayesian models</em>: generative models in which there are several levels of latent random choices that affect the observed data. In particular a hierarchical model is usually one in which there is a branching structure in the dependence diagram, such that the &ldquo;deepest&rdquo; choices affect all the data, but they only do so through a set of more shallow choices which each affect some of the data, and so on.</p>

<p>Many examples of hierarchical models are even simpler than the categorization examples above. The fair vs. unfair model selection example from Chapter 8 was already a simple hierarchical model; this example exhibits an abrupt (non-linear) transition from believing in a coin weight near 0.5 to one near 0.9. Such relatively abrupt transitions, and more generally complex non-linear learning curves, are characteristic of hierarchical models.</p>

<p>Hierarchical model structures will generally give rise to a number of important learning phenomena: transfer learning (or learning-to-learn), the blessing of abstraction, and fairly abrupt transitions.</p>

<h2>Hierarchical Abstraction versus Lambda Abstraction</h2>

<p>We have spoken of the earlier choices in a hierarchical model as being more &ldquo;abstract.&rdquo; In computer science the <code>fn</code> operator (lambda) is often called lambda abstraction. Are these two uses of &ldquo;abstract&rdquo; related?</p>

<p>There is a third notion of abstraction in a generative model which may explain the relation between these two: if we have a designated set of observations (or more generally a function that we think of as generating &ldquo;perceptual&rdquo; data) we can say that a random choice is abstract if it is far from the data. More specifically the degree of abstraction of an expression in a probabilistic program is the number of immediate causal dependencies (edges) from the expression to the designated observation expression (note that this is a partial, not strict, ordering on the random choices).</p>

<p>In a hierarchically structured model the deeper random choices are more abstract in this sense of causal distance from the data. More subtly, when a procedure is created with <code>fn</code> the expressions inside this procedure will tend to be more causally distant from the data (since the procedure must be applied before these expressions can be used), and hence greater depth of lambda abstraction will tend to lead to greater abstraction in the causal distance sense.</p>


<h1 id="references"><a href="#references">References</a></h1>

<p>Chomsky, N. (1970). Remarks on Nominalization. In R. A. Jacobs &amp; P. S. Rosenbaum (Eds.), <em>Readings in English Transformational Grammar</em> (pp. 184&ndash;221). Waltham, Mass: Ginn.</p>
<p>Jackendoff, R. S. (1981). <em>X&prime; Syntax: A Study of Phrase Structure</em>. Linguistic inquiry monographs. MIT Press.</p>
<p>Kemp, C., Perfors, A., &amp; Tenenbaum, J. B. (2007). Learning overhypotheses with hierarchical Bayesian models. <em>Developmental Science</em>.</p>
<p>Nisbett, R. E., Krantz, D. H., Jepson, C., &amp; Kunda, Z. (1983). The use of statistical heuristics in everyday inductive reasoning. <em>Psychological Review</em>, <em>90</em>(4), 339.</p>
<p>Salakhutdinov, R., Tenenbaum, J., &amp; Torralba, A. (2010). <em>One-shot learning with a hierarchical nonparametric Bayesian model</em>.</p>
<p>Smith, L. B., Jones, S. S., Landau, B., Gershkoff-Stowe, L., &amp; Samuelson, L. (2002). Object name learning provides on-the-job training for attention. <em>Psychological Science</em>, <em>13</em>(1), 13&ndash;19.</p>


  </div>
  <div class="chapter-nav">
    <a href="08-learning-as-conditional-inference.html">&larr; Chapter 8: Learning as Conditional Inference</a>
    <span></span>
  </div>
</div>

<!-- Interactive runner: loads prob-cljs via fetch + eval_string -->
<script>
var _scittleReady = false;
var _scittleLoading = null;

function ensureScittleImports() {
  if (_scittleReady) return Promise.resolve();
  if (_scittleLoading) return _scittleLoading;

  var files = [
    '../prob/math.cljs',
    '../prob/erp.cljs',
    '../prob/dist.cljs',
    '../prob/inference.cljs',
    '../prob/builtins.cljs',
    '../prob/core.cljs',
    'viz.cljs'
  ];

  _scittleLoading = Promise.all(files.map(function(f) {
    return fetch(f).then(function(r) {
      if (!r.ok) throw new Error('Failed to load ' + f + ': ' + r.status);
      return r.text();
    });
  })).then(function(sources) {
    sources.forEach(function(src) { scittle.core.eval_string(src); });

    scittle.core.eval_string(
      "(ns prob.macros)" +
      "(defmacro rejection-query [& body] `(prob.core/rejection-query-fn (fn [] ~@body)))" +
      "(defmacro mh-query [n lag & body] `(prob.core/mh-query-fn ~n ~lag (fn [] ~@body)))" +
      "(defmacro enumeration-query [& body] `(prob.core/enumeration-query-fn (fn [] ~@body)))"
    );

    scittle.core.eval_string(
      "(require '[prob.core :refer [flip gaussian uniform uniform-draw random-integer multinomial" +
      "                              sample-discrete beta gamma dirichlet exponential" +
      "                              binomial poisson categorical" +
      "                              condition factor observe rejection-query-fn mh-query-fn" +
      "                              enumeration-query-fn mem mean variance sum prod" +
      "                              sample* observe* dist? enumerate*]])" +
      "(require '[prob.dist :refer [observe* sample* dist? enumerate*" +
      "                              gaussian-dist bernoulli-dist uniform-dist beta-dist gamma-dist" +
      "                              exponential-dist dirichlet-dist uniform-draw-dist" +
      "                              random-integer-dist multinomial-dist sample-discrete-dist" +
      "                              binomial-dist poisson-dist categorical-dist]])" +
      "(require '[prob.builtins :refer [expt member pair null? equal? make-list length" +
      "                                  string-append abs sample fold iota]])" +
      "(require '[prob.macros :refer [rejection-query mh-query enumeration-query]])" +
      "(require '[prob.viz :refer [hist density scatter barplot lineplot display run-physics animate-physics]])"
    );

    _scittleReady = true;
  });

  return _scittleLoading;
}

function runCode(code, output) {
  output.innerHTML = '';
  window.__currentOutput = output;
  window.__appendToOutput = function(el) { window.__currentOutput.appendChild(el); };
  window.__appendTextToOutput = function(text) {
    var span = document.createElement('span');
    span.textContent = text + '\n';
    window.__currentOutput.appendChild(span);
  };
  ensureScittleImports().then(function() {
    window.__currentOutput = output;
    try {
      var result = scittle.core.eval_string(code);
      if (result != null) {
        var span = document.createElement('span');
        span.textContent = '' + result;
        output.appendChild(span);
      }
    } catch(e) {
      var span = document.createElement('span');
      span.className = 'error';
      span.textContent = 'Error: ' + e.message;
      output.appendChild(span);
    }
  }).catch(function(e) {
    var span = document.createElement('span');
    span.className = 'error';
    span.textContent = 'Load error: ' + e.message;
    output.appendChild(span);
  });
}

document.querySelectorAll('#chapter pre:not(.norun)').forEach(function(pre) {
  var codeEl = pre.querySelector('code');
  if (!codeEl) return;
  var code = codeEl.textContent.trim();

  var container = document.createElement('div');
  container.className = 'code-example';

  var editorDiv = document.createElement('div');

  var toolbar = document.createElement('div');
  toolbar.className = 'toolbar';

  var btn = document.createElement('button');
  btn.textContent = 'Run';

  var output = document.createElement('div');
  output.className = 'output';

  toolbar.appendChild(btn);
  container.appendChild(editorDiv);
  container.appendChild(toolbar);
  container.appendChild(output);
  pre.replaceWith(container);

  var editor = ProbEditor.createEditor(editorDiv, code, {
    onEval: function(code) { runCode(code, output); }
  });

  btn.addEventListener('click', function() {
    runCode(editor.getCode(), output);
  });
});
</script>
</body>
</html>
