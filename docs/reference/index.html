<!DOCTYPE html>
<html>
<head>
  <title>prob-cljs API Reference</title>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js" onload="renderMathInElement(document.body,{delimiters:[{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}]})"></script>
  <script src="../js/editor.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/scittle@0.7.28/dist/scittle.js" crossorigin="anonymous"></script>
</head>
<body>
<div id="header">
  <div id="logotype"><a href="../index.html">prob-cljs</a></div>
  <ul id="nav">
    <li><a href="../index.html">Home</a></li>
    <li><a href="../probmods/index.html">ProbMods</a></li>
    <li><a href="https://github.com/robert-johansson/prob-cljs">GitHub</a></li>
  </ul>
</div>

<div id="page-wrapper">
<nav id="sidebar">
  <div class="sidebar-title">API Reference</div>
  <ul>
    <li class="section-group"><a href="#erp">Elementary Random Primitives</a></li>
    <li class="sub-group"><a href="#discrete-erps">Discrete</a></li>
    <li><a href="#flip">flip</a></li>
    <li><a href="#uniform-draw">uniform-draw</a></li>
    <li><a href="#random-integer">random-integer</a></li>
    <li><a href="#multinomial">multinomial</a></li>
    <li><a href="#sample-discrete">sample-discrete</a></li>
    <li><a href="#categorical">categorical</a></li>
    <li><a href="#binomial">binomial</a></li>
    <li><a href="#poisson">poisson</a></li>
    <li class="sub-group"><a href="#continuous-erps">Continuous</a></li>
    <li><a href="#gaussian">gaussian</a></li>
    <li><a href="#uniform">uniform</a></li>
    <li><a href="#beta">beta</a></li>
    <li><a href="#gamma-erp">gamma</a></li>
    <li><a href="#exponential-erp">exponential</a></li>
    <li><a href="#dirichlet-erp">dirichlet</a></li>
    <li class="sub-group"><a href="#prng">PRNG</a></li>
    <li><a href="#rand">rand</a></li>
    <li><a href="#set-seed">set-seed!</a></li>

    <li class="section-group"><a href="#distributions">Distributions</a></li>
    <li class="sub-group"><a href="#discrete-distributions">Discrete</a></li>
    <li><a href="#bernoulli-dist">bernoulli-dist</a></li>
    <li><a href="#categorical-dist">categorical-dist</a></li>
    <li><a href="#uniform-draw-dist">uniform-draw-dist</a></li>
    <li><a href="#uniform-discrete-dist">uniform-discrete-dist</a></li>
    <li><a href="#random-integer-dist">random-integer-dist</a></li>
    <li><a href="#multinomial-dist">multinomial-dist</a></li>
    <li><a href="#sample-discrete-dist">sample-discrete-dist</a></li>
    <li><a href="#binomial-dist">binomial-dist</a></li>
    <li><a href="#poisson-dist">poisson-dist</a></li>
    <li><a href="#delta-dist">delta-dist</a></li>
    <li class="sub-group"><a href="#continuous-distributions">Continuous</a></li>
    <li><a href="#gaussian-dist">gaussian-dist</a></li>
    <li><a href="#uniform-dist">uniform-dist</a></li>
    <li><a href="#beta-dist">beta-dist</a></li>
    <li><a href="#gamma-dist">gamma-dist</a></li>
    <li><a href="#exponential-dist">exponential-dist</a></li>
    <li><a href="#cauchy-dist">cauchy-dist</a></li>
    <li><a href="#laplace-dist">laplace-dist</a></li>
    <li><a href="#lognormal-dist">lognormal-dist</a></li>
    <li><a href="#student-t-dist">student-t-dist</a></li>
    <li><a href="#chi-squared-dist">chi-squared-dist</a></li>
    <li><a href="#logit-normal-dist">logit-normal-dist</a></li>
    <li class="sub-group"><a href="#compound-distributions">Compound</a></li>
    <li><a href="#mixture-dist">mixture-dist</a></li>
    <li><a href="#kde-dist">kde-dist</a></li>
    <li><a href="#marginal-dist">marginal-dist</a></li>
    <li class="sub-group"><a href="#dist-utilities">Utilities</a></li>
    <li><a href="#entropy">entropy</a></li>
    <li><a href="#kl-divergence">kl-divergence</a></li>
    <li><a href="#discrete-pred">discrete? / continuous?</a></li>
    <li><a href="#dist-pred">dist?</a></li>

    <li class="section-group"><a href="#inference">Inference</a></li>
    <li><a href="#rejection-query">rejection-query</a></li>
    <li><a href="#mh-query">mh-query</a></li>
    <li><a href="#enumeration-query">enumeration-query</a></li>
    <li><a href="#forward-query">forward-query</a></li>
    <li><a href="#importance-query">importance-query</a></li>
    <li><a href="#map-query">map-query</a></li>
    <li><a href="#mh-query-scored">mh-query-scored</a></li>
    <li><a href="#infer">infer</a></li>

    <li class="section-group"><a href="#conditioning">Conditioning</a></li>
    <li><a href="#condition">condition</a></li>
    <li><a href="#factor">factor</a></li>
    <li><a href="#observe">observe</a></li>
    <li><a href="#condition-equal">condition-equal</a></li>

    <li class="section-group"><a href="#utilities">Utilities</a></li>
    <li class="sub-group"><a href="#statistics">Statistics</a></li>
    <li><a href="#mean">mean</a></li>
    <li><a href="#variance-fn">variance / sd</a></li>
    <li><a href="#sum-prod">sum / prod</a></li>
    <li><a href="#mode">mode</a></li>
    <li><a href="#weighted-mean">weighted-mean</a></li>
    <li><a href="#weighted-variance">weighted-variance</a></li>
    <li><a href="#expectation">expectation</a></li>
    <li><a href="#empirical-distribution">empirical-distribution</a></li>
    <li><a href="#softmax">softmax</a></li>
    <li class="sub-group"><a href="#memoization">Memoization</a></li>
    <li><a href="#mem">mem</a></li>
    <li><a href="#cache">cache</a></li>
    <li><a href="#DPmem">DPmem</a></li>
    <li class="sub-group"><a href="#list-primitives">List Primitives</a></li>
    <li><a href="#pair">pair</a></li>
    <li><a href="#car-cdr">car / cdr</a></li>
    <li><a href="#repeat-fn">repeat-fn</a></li>

    <li class="section-group"><a href="#math">Math</a></li>
    <li><a href="#log-gamma-fn">log-gamma-fn</a></li>
    <li><a href="#log-beta-fn">log-beta-fn</a></li>
    <li><a href="#log-fact">log-fact</a></li>
    <li><a href="#log-sum-exp">log-sum-exp</a></li>
    <li><a href="#digamma">digamma</a></li>
    <li><a href="#erf">erf</a></li>

    <li class="section-group"><a href="#visualization">Visualization</a></li>
    <li><a href="#display-viz">display</a></li>
    <li><a href="#hist">hist</a></li>
    <li><a href="#density-viz">density</a></li>
    <li><a href="#barplot">barplot</a></li>
    <li><a href="#scatter-viz">scatter</a></li>
    <li><a href="#lineplot-viz">lineplot</a></li>
    <li><a href="#table-viz">table</a></li>
    <li><a href="#heatmap-viz">heatmap</a></li>
    <li><a href="#marginals-viz">marginals</a></li>
    <li><a href="#auto-viz">auto</a></li>
  </ul>
</nav>

<div id="content">
<h1 id="page-title">API Reference</h1>
<p>Interactive reference for the prob-cljs probabilistic programming library. All code examples are editable and runnable in the browser. Functions are available via <code>(require '[prob.core :as prob])</code> or imported individually.</p>

<!-- ============================================================ -->
<h2 id="erp"><a href="#erp">Elementary Random Primitives</a></h2>
<p>ERPs are trace-aware sampling functions that return samples directly. Inside inference (e.g. <code>mh-query</code>), random choices are traced and can be replayed or proposed to. Outside inference, ERPs are pure samplers with no side effects. For scoring observed data, use <a href="#distributions">distribution objects</a> with <code>observe</code> instead.</p>

<h3 id="discrete-erps"><a href="#discrete-erps">Discrete ERPs</a></h3>

<div class="fn-entry" id="flip">
<h3><a href="#flip"><code>flip</code></a></h3>
<div class="fn-signature">(flip) (flip p)</div>
<p class="fn-description">Bernoulli trial. Returns <code>true</code> with probability <em>p</em> (default 0.5), <code>false</code> otherwise. The simplest random primitive.</p>
<pre><code>(hist (repeatedly 1000 flip) "fair coin")
(hist (repeatedly 1000 #(flip 0.8)) "biased coin p=0.8")</code></pre>
</div>

<div class="fn-entry" id="uniform-draw">
<h3><a href="#uniform-draw"><code>uniform-draw</code></a></h3>
<div class="fn-signature">(uniform-draw lst)</div>
<p class="fn-description">Pick an element uniformly at random from a list. Each item has equal probability \(1/n\).</p>
<pre><code>(hist (repeatedly 1000 #(uniform-draw ["red" "green" "blue"])) "uniform draw")</code></pre>
</div>

<div class="fn-entry" id="random-integer">
<h3><a href="#random-integer"><code>random-integer</code></a></h3>
<div class="fn-signature">(random-integer n)</div>
<p class="fn-description">Sample a uniform random integer in [0, <em>n</em>). Each integer has probability \(1/n\).</p>
<pre><code>(hist (repeatedly 1000 #(random-integer 6)) "integers [0, 6)")</code></pre>
</div>

<div class="fn-entry" id="multinomial">
<h3><a href="#multinomial"><code>multinomial</code></a></h3>
<div class="fn-signature">(multinomial items probs)</div>
<p class="fn-description">Weighted draw from labeled items. Weights are normalized to probabilities.</p>
<pre><code>(hist (repeatedly 1000 #(multinomial ["a" "b" "c"] [1 2 7])) "weighted draw")</code></pre>
</div>

<div class="fn-entry" id="sample-discrete">
<h3><a href="#sample-discrete"><code>sample-discrete</code></a></h3>
<div class="fn-signature">(sample-discrete weights)</div>
<p class="fn-description">Weighted index selection. Returns an integer index in [0, <em>n</em>), where each index is chosen with probability proportional to its weight.</p>
<pre><code>(hist (repeatedly 1000 #(sample-discrete [1 2 7])) "weighted index")</code></pre>
</div>

<div class="fn-entry" id="categorical">
<h3><a href="#categorical"><code>categorical</code></a></h3>
<div class="fn-signature">(categorical weight-map) (categorical categories weights)</div>
<p class="fn-description">Weighted discrete choice. Accepts either a map <code>{category weight ...}</code> or two sequences of categories and weights.</p>
<pre><code>(hist (repeatedly 1000 #(categorical {"cat" 3 "dog" 5 "fish" 2})) "from map")
(hist (repeatedly 1000 #(categorical ["a" "b" "c"] [1 1 8])) "from seqs")</code></pre>
</div>

<div class="fn-entry" id="binomial">
<h3><a href="#binomial"><code>binomial</code></a></h3>
<div class="fn-signature">(binomial n p)</div>
<p class="fn-description">Number of successes in <em>n</em> Bernoulli trials with probability <em>p</em>. Returns an integer in [0, <em>n</em>].</p>
<pre><code>(hist (repeatedly 1000 #(binomial 10 0.3)) "Binomial(10, 0.3)")</code></pre>
</div>

<div class="fn-entry" id="poisson">
<h3><a href="#poisson"><code>poisson</code></a></h3>
<div class="fn-signature">(poisson lambda)</div>
<p class="fn-description">Poisson count with rate \(\lambda\). Models the number of events in a fixed interval.</p>
<pre><code>(hist (repeatedly 1000 #(poisson 4)) "Poisson(4)")</code></pre>
</div>

<h3 id="continuous-erps"><a href="#continuous-erps">Continuous ERPs</a></h3>

<div class="fn-entry" id="gaussian">
<h3><a href="#gaussian"><code>gaussian</code></a></h3>
<div class="fn-signature">(gaussian) (gaussian mu sigma)</div>
<p class="fn-description">Sample from a Gaussian (normal) distribution with mean <em>mu</em> and standard deviation <em>sigma</em>. Defaults to \(\mathcal{N}(0, 1)\).</p>
<pre><code>(density (repeatedly 1000 gaussian) "standard normal N(0,1)")
(density (repeatedly 1000 #(gaussian 5 2)) "N(5, 2)")</code></pre>
</div>

<div class="fn-entry" id="uniform">
<h3><a href="#uniform"><code>uniform</code></a></h3>
<div class="fn-signature">(uniform a b)</div>
<p class="fn-description">Sample from a continuous uniform distribution on [<em>a</em>, <em>b</em>].</p>
<pre><code>(density (repeatedly 1000 #(uniform 0 10)) "Uniform(0, 10)")</code></pre>
</div>

<div class="fn-entry" id="beta">
<h3><a href="#beta"><code>beta</code></a></h3>
<div class="fn-signature">(beta a b)</div>
<p class="fn-description">Sample from a Beta distribution with shape parameters <em>a</em> and <em>b</em>. Returns a value in (0, 1). Commonly used as a prior for probabilities.</p>
<pre><code>(density (repeatedly 1000 #(beta 2 5)) "Beta(2, 5)")
(density (repeatedly 1000 #(beta 0.5 0.5)) "Beta(0.5, 0.5)")</code></pre>
</div>

<div class="fn-entry" id="gamma-erp">
<h3><a href="#gamma-erp"><code>gamma</code></a></h3>
<div class="fn-signature">(gamma shape scale)</div>
<p class="fn-description">Sample from a Gamma distribution with given <em>shape</em> and <em>scale</em>. Returns a positive value. Useful as a prior for rates and variances.</p>
<pre><code>(density (repeatedly 1000 #(gamma 2 2)) "Gamma(shape=2, scale=2)")</code></pre>
</div>

<div class="fn-entry" id="exponential-erp">
<h3><a href="#exponential-erp"><code>exponential</code></a></h3>
<div class="fn-signature">(exponential rate)</div>
<p class="fn-description">Sample from an Exponential distribution with given <em>rate</em>. Models time between events. Mean is \(1/\text{rate}\).</p>
<pre><code>(density (repeatedly 1000 #(exponential 0.5)) "Exponential(rate=0.5)")</code></pre>
</div>

<div class="fn-entry" id="dirichlet-erp">
<h3><a href="#dirichlet-erp"><code>dirichlet</code></a></h3>
<div class="fn-signature">(dirichlet alpha-vec)</div>
<p class="fn-description">Sample from a Dirichlet distribution. Returns a vector of probabilities that sum to 1. The length matches <em>alpha-vec</em>.</p>
<pre><code>;; Symmetric Dirichlet — roughly uniform simplex
(display (mapv #(.toFixed % 3) (dirichlet [1 1 1])))
;; Concentrated Dirichlet — peaked toward equal proportions
(display (mapv #(.toFixed % 3) (dirichlet [10 10 10])))</code></pre>
</div>

<h3 id="prng"><a href="#prng">PRNG</a></h3>

<div class="fn-entry" id="rand">
<h3><a href="#rand"><code>rand</code></a></h3>
<div class="fn-signature">(rand)</div>
<p class="fn-description">Raw uniform random double in [0, 1) from the seedable xoshiro128** PRNG. All ERPs use this internally.</p>
<pre><code>(display "random:" (.toFixed (rand) 6))
(display "random:" (.toFixed (rand) 6))
(display "random:" (.toFixed (rand) 6))</code></pre>
</div>

<div class="fn-entry" id="set-seed">
<h3><a href="#set-seed"><code>set-seed!</code></a></h3>
<div class="fn-signature">(set-seed!) (set-seed! n)</div>
<p class="fn-description">Seed the PRNG for reproducible results. With an integer argument, produces a deterministic sequence. With no arguments, re-initializes from system entropy.</p>
<pre><code>;; Same seed → same sequence
(set-seed! 42)
(display "first:" (.toFixed (rand) 6))
(display "second:" (.toFixed (rand) 6))
;; Reset to same seed → same results
(set-seed! 42)
(display "first again:" (.toFixed (rand) 6))
(display "second again:" (.toFixed (rand) 6))</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="distributions"><a href="#distributions">Distributions</a></h2>
<p>Distribution objects are first-class values that encapsulate sampling and scoring. They implement up to three protocols:</p>
<ul>
<li><strong>IDistribution</strong> &mdash; <code>sample*</code> and <code>observe*</code>. Draw random samples and compute log-probabilities. All 24 distributions implement this.</li>
<li><strong>IEnumerable</strong> &mdash; <code>enumerate*</code>. Returns the support (all possible values). Implemented by discrete distributions with finite support.</li>
<li><strong>IProposable</strong> &mdash; <code>propose*</code> and <code>propose-lp</code>. Drift proposals for efficient Metropolis-Hastings mixing. Implemented by 8 distributions.</li>
</ul>
<p>Use distribution objects (vs. ERP functions) when you need to <code>observe</code> data, compose distributions with <code>mixture-dist</code>, or pass distributions as first-class values.</p>
<pre><code>;; Three protocols in action
(let [d (bernoulli-dist 0.7)]
  ;; IDistribution — every distribution has these
  (display "sample:" (sample* d))
  (display "log P(true):" (.toFixed (observe* d true) 4))
  ;; IEnumerable — discrete distributions only
  (display "support:" (enumerate* d))
  ;; Type predicates
  (display "discrete?:" (discrete? d))
  (display "continuous?:" (continuous? (gaussian-dist))))</code></pre>

<h3 id="discrete-distributions"><a href="#discrete-distributions">Discrete Distributions</a></h3>
<p>Discrete distributions return values from a finite or countable set. Those with finite support implement <code>IEnumerable</code> for exact enumeration-based inference.</p>

<div class="fn-entry" id="bernoulli-dist">
<h3><a href="#bernoulli-dist"><code>bernoulli-dist</code></a></h3>
<div class="fn-signature">(bernoulli-dist) (bernoulli-dist p)</div>
<p class="fn-description">Bernoulli distribution. Returns <code>true</code> with probability <em>p</em> (default 0.5), <code>false</code> otherwise. Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (bernoulli-dist 0.7)]
  (display "sample:" (sample* d))
  (display "log P(true):" (.toFixed (observe* d true) 4))
  (display "log P(false):" (.toFixed (observe* d false) 4))
  (display "support:" (enumerate* d)))</code></pre>
</div>

<div class="fn-entry" id="categorical-dist">
<h3><a href="#categorical-dist"><code>categorical-dist</code></a></h3>
<div class="fn-signature">(categorical-dist weight-map) (categorical-dist categories weights)</div>
<p class="fn-description">Categorical distribution over labeled categories with given weights. Accepts a map <code>{category weight ...}</code> or two sequences. Weights are normalized. Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (categorical-dist {"cat" 3 "dog" 5 "fish" 2})]
  (display "sample:" (sample* d))
  (display "log P(dog):" (.toFixed (observe* d "dog") 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "categorical draws"))</code></pre>
</div>

<div class="fn-entry" id="uniform-draw-dist">
<h3><a href="#uniform-draw-dist"><code>uniform-draw-dist</code></a></h3>
<div class="fn-signature">(uniform-draw-dist items)</div>
<p class="fn-description">Discrete uniform distribution over items. Equal probability for each distinct item. Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (uniform-draw-dist ["red" "green" "blue"])]
  (display "sample:" (sample* d))
  (display "log P(red):" (.toFixed (observe* d "red") 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "uniform draws"))</code></pre>
</div>

<div class="fn-entry" id="uniform-discrete-dist">
<h3><a href="#uniform-discrete-dist"><code>uniform-discrete-dist</code></a></h3>
<div class="fn-signature">(uniform-discrete-dist lo hi)</div>
<p class="fn-description">Discrete uniform over integers [<em>lo</em>, <em>hi</em>] inclusive. Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (uniform-discrete-dist 1 6)]
  (display "sample:" (sample* d))
  (display "log P(3):" (.toFixed (observe* d 3) 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "dice rolls"))</code></pre>
</div>

<div class="fn-entry" id="random-integer-dist">
<h3><a href="#random-integer-dist"><code>random-integer-dist</code></a></h3>
<div class="fn-signature">(random-integer-dist n)</div>
<p class="fn-description">Discrete uniform over integers [0, <em>n</em>). Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (random-integer-dist 4)]
  (display "sample:" (sample* d))
  (display "log P(0):" (.toFixed (observe* d 0) 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "random integers [0,4)"))</code></pre>
</div>

<div class="fn-entry" id="multinomial-dist">
<h3><a href="#multinomial-dist"><code>multinomial-dist</code></a></h3>
<div class="fn-signature">(multinomial-dist items probs)</div>
<p class="fn-description">Weighted discrete distribution over labeled items. Weights are normalized to probabilities. Supports <code>enumerate*</code> and drift proposals.</p>
<pre><code>(let [d (multinomial-dist ["a" "b" "c"] [1 2 7])]
  (display "sample:" (sample* d))
  (display "log P(c):" (.toFixed (observe* d "c") 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "weighted draws"))</code></pre>
</div>

<div class="fn-entry" id="sample-discrete-dist">
<h3><a href="#sample-discrete-dist"><code>sample-discrete-dist</code></a></h3>
<div class="fn-signature">(sample-discrete-dist weights)</div>
<p class="fn-description">Weighted discrete distribution over indices [0, <em>n</em>). Returns an integer index, weighted by the given weights. Supports <code>enumerate*</code>.</p>
<pre><code>(let [d (sample-discrete-dist [1 2 7])]
  (display "sample index:" (sample* d))
  (display "log P(idx=2):" (.toFixed (observe* d 2) 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "weighted index selection"))</code></pre>
</div>

<div class="fn-entry" id="binomial-dist">
<h3><a href="#binomial-dist"><code>binomial-dist</code></a></h3>
<div class="fn-signature">(binomial-dist n p)</div>
<p class="fn-description">Binomial distribution: number of successes in <em>n</em> Bernoulli trials with probability <em>p</em>. Supports <code>enumerate*</code> (support is 0 to <em>n</em>).</p>
<pre><code>(let [d (binomial-dist 10 0.3)]
  (display "sample:" (sample* d))
  (display "log P(3):" (.toFixed (observe* d 3) 4))
  (display "support:" (enumerate* d))
  (hist (repeatedly 1000 #(sample* d)) "Binomial(10, 0.3)"))</code></pre>
</div>

<div class="fn-entry" id="poisson-dist">
<h3><a href="#poisson-dist"><code>poisson-dist</code></a></h3>
<div class="fn-signature">(poisson-dist lambda)</div>
<p class="fn-description">Poisson distribution with rate \(\lambda\). Counts events in a fixed interval. Discrete but with infinite support &mdash; does not support <code>enumerate*</code>.</p>
<pre><code>(let [d (poisson-dist 4.0)]
  (display "sample:" (sample* d))
  (display "log P(4):" (.toFixed (observe* d 4) 4))
  (display "log P(0):" (.toFixed (observe* d 0) 4))
  (hist (repeatedly 1000 #(sample* d)) "Poisson(4)"))</code></pre>
</div>

<div class="fn-entry" id="delta-dist">
<h3><a href="#delta-dist"><code>delta-dist</code></a></h3>
<div class="fn-signature">(delta-dist v)</div>
<p class="fn-description">Delta (point mass) distribution. Always returns <em>v</em>. <code>observe*</code> returns 0 for <em>v</em>, \(-\infty\) for anything else. Supports <code>enumerate*</code>.</p>
<pre><code>(let [d (delta-dist 42)]
  (display "sample:" (sample* d))
  (display "log P(42):" (observe* d 42))
  (display "log P(0):" (observe* d 0))
  (display "support:" (enumerate* d)))</code></pre>
</div>

<h3 id="continuous-distributions"><a href="#continuous-distributions">Continuous Distributions</a></h3>
<p>Continuous distributions return real-valued samples. Use <code>observe*</code> to compute the log-density at a point.</p>

<div class="fn-entry" id="gaussian-dist">
<h3><a href="#gaussian-dist"><code>gaussian-dist</code></a></h3>
<div class="fn-signature">(gaussian-dist) (gaussian-dist mu sigma)</div>
<p class="fn-description">Gaussian (normal) distribution with mean \(\mu\) and standard deviation \(\sigma\). Defaults to \(\mathcal{N}(0, 1)\). Supports drift proposals for efficient MH sampling.</p>
<pre><code>(let [d (gaussian-dist 0 1)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0):" (.toFixed (observe* d 0) 4))
  (display "log p(1.96):" (.toFixed (observe* d 1.96) 4))
  (density (repeatedly 1000 #(sample* d)) "N(0, 1)"))</code></pre>
</div>

<div class="fn-entry" id="uniform-dist">
<h3><a href="#uniform-dist"><code>uniform-dist</code></a></h3>
<div class="fn-signature">(uniform-dist a b)</div>
<p class="fn-description">Continuous uniform distribution on [<em>a</em>, <em>b</em>]. Constant density \(1/(b-a)\) within the interval, zero outside.</p>
<pre><code>(let [d (uniform-dist 0 10)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(5):" (.toFixed (observe* d 5) 4))
  (display "log p(11):" (observe* d 11))
  (density (repeatedly 1000 #(sample* d)) "Uniform(0, 10)"))</code></pre>
</div>

<div class="fn-entry" id="beta-dist">
<h3><a href="#beta-dist"><code>beta-dist</code></a></h3>
<div class="fn-signature">(beta-dist a b)</div>
<p class="fn-description">Beta distribution with shape parameters <em>a</em> (\(\alpha\)) and <em>b</em> (\(\beta\)). Values in (0, 1). Commonly used as a prior for probabilities. Supports drift proposals.</p>
<pre><code>(let [d (beta-dist 2 5)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0.3):" (.toFixed (observe* d 0.3) 4))
  (density (repeatedly 1000 #(sample* d)) "Beta(2, 5)"))</code></pre>
</div>

<div class="fn-entry" id="gamma-dist">
<h3><a href="#gamma-dist"><code>gamma-dist</code></a></h3>
<div class="fn-signature">(gamma-dist shape scale)</div>
<p class="fn-description">Gamma distribution with given <em>shape</em> and <em>scale</em>. Values in (0, \(\infty\)). Useful as a prior for positive quantities like rates and variances.</p>
<pre><code>(let [d (gamma-dist 2 2)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(3):" (.toFixed (observe* d 3) 4))
  (density (repeatedly 1000 #(sample* d)) "Gamma(shape=2, scale=2)"))</code></pre>
</div>

<div class="fn-entry" id="exponential-dist">
<h3><a href="#exponential-dist"><code>exponential-dist</code></a></h3>
<div class="fn-signature">(exponential-dist rate)</div>
<p class="fn-description">Exponential distribution with given <em>rate</em> (inverse scale). Models time between events. Mean is \(1/\text{rate}\).</p>
<pre><code>(let [d (exponential-dist 0.5)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(2):" (.toFixed (observe* d 2) 4))
  (density (repeatedly 1000 #(sample* d)) "Exponential(rate=0.5)"))</code></pre>
</div>

<div class="fn-entry" id="cauchy-dist">
<h3><a href="#cauchy-dist"><code>cauchy-dist</code></a></h3>
<div class="fn-signature">(cauchy-dist location scale)</div>
<p class="fn-description">Cauchy distribution with given <em>location</em> and <em>scale</em>. Heavy-tailed: no finite mean or variance. Useful as a robust alternative to the Gaussian.</p>
<pre><code>(let [d (cauchy-dist 0 1)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0):" (.toFixed (observe* d 0) 4))
  (density (repeatedly 1000 #(sample* d)) "Cauchy(0, 1)"))</code></pre>
</div>

<div class="fn-entry" id="laplace-dist">
<h3><a href="#laplace-dist"><code>laplace-dist</code></a></h3>
<div class="fn-signature">(laplace-dist location scale)</div>
<p class="fn-description">Laplace (double exponential) distribution. Sharper peak and heavier tails than Gaussian. Useful for sparse priors (L1 regularization).</p>
<pre><code>(let [d (laplace-dist 0 1)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0):" (.toFixed (observe* d 0) 4))
  (density (repeatedly 1000 #(sample* d)) "Laplace(0, 1)"))</code></pre>
</div>

<div class="fn-entry" id="lognormal-dist">
<h3><a href="#lognormal-dist"><code>lognormal-dist</code></a></h3>
<div class="fn-signature">(lognormal-dist mu sigma)</div>
<p class="fn-description">Log-normal distribution: \(\exp(\mathcal{N}(\mu, \sigma))\). Values in (0, \(\infty\)). Useful for modeling positive quantities with multiplicative noise.</p>
<pre><code>(let [d (lognormal-dist 0 0.5)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(1):" (.toFixed (observe* d 1) 4))
  (density (repeatedly 1000 #(sample* d)) "LogNormal(0, 0.5)"))</code></pre>
</div>

<div class="fn-entry" id="student-t-dist">
<h3><a href="#student-t-dist"><code>student-t-dist</code></a></h3>
<div class="fn-signature">(student-t-dist df) (student-t-dist df location scale)</div>
<p class="fn-description">Student's t-distribution with <em>df</em> degrees of freedom, optional <em>location</em> and <em>scale</em> (default 0 and 1). Heavier tails than Gaussian; approaches \(\mathcal{N}\) as \(\nu \to \infty\).</p>
<pre><code>(let [d (student-t-dist 3)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0):" (.toFixed (observe* d 0) 4))
  (density (repeatedly 1000 #(sample* d)) "Student-t(df=3)"))</code></pre>
</div>

<div class="fn-entry" id="chi-squared-dist">
<h3><a href="#chi-squared-dist"><code>chi-squared-dist</code></a></h3>
<div class="fn-signature">(chi-squared-dist df)</div>
<p class="fn-description">Chi-squared distribution with <em>df</em> degrees of freedom. Equivalent to \(\text{Gamma}(df/2, 2)\). Commonly used in goodness-of-fit tests.</p>
<pre><code>(let [d (chi-squared-dist 4)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(3):" (.toFixed (observe* d 3) 4))
  (density (repeatedly 1000 #(sample* d)) "Chi-squared(df=4)"))</code></pre>
</div>

<div class="fn-entry" id="logit-normal-dist">
<h3><a href="#logit-normal-dist"><code>logit-normal-dist</code></a></h3>
<div class="fn-signature">(logit-normal-dist mu sigma)</div>
<p class="fn-description">Logit-normal distribution: \(\text{sigmoid}(\mathcal{N}(\mu, \sigma))\). Values in (0, 1). Alternative to Beta for modeling proportions.</p>
<pre><code>(let [d (logit-normal-dist 0 1)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(0.5):" (.toFixed (observe* d 0.5) 4))
  (density (repeatedly 1000 #(sample* d)) "LogitNormal(0, 1)"))</code></pre>
</div>

<h3 id="compound-distributions"><a href="#compound-distributions">Compound Distributions</a></h3>
<p>Compound distributions build new distributions from existing ones or from data.</p>

<div class="fn-entry" id="mixture-dist">
<h3><a href="#mixture-dist"><code>mixture-dist</code></a></h3>
<div class="fn-signature">(mixture-dist components weights)</div>
<p class="fn-description">Mixture of distributions. <em>components</em> is a sequence of distribution objects, <em>weights</em> are mixing proportions (need not sum to 1, will be normalized). The log-probability is computed via log-sum-exp over components.</p>
<pre><code>(let [d (mixture-dist [(gaussian-dist -2 0.5) (gaussian-dist 2 0.5)] [1 1])]
  (display "log p(0):" (.toFixed (observe* d 0) 4))
  (density (repeatedly 1000 #(sample* d)) "bimodal mixture"))</code></pre>
</div>

<div class="fn-entry" id="kde-dist">
<h3><a href="#kde-dist"><code>kde-dist</code></a></h3>
<div class="fn-signature">(kde-dist data) (kde-dist data bandwidth)</div>
<p class="fn-description">Kernel density estimation with Gaussian kernels. Turns a collection of samples into a smooth continuous distribution. Bandwidth defaults to Silverman's rule of thumb.</p>
<pre><code>(let [data [1.2 1.5 2.0 2.3 2.8 3.1]
      d (kde-dist data)]
  (display "sample:" (.toFixed (sample* d) 4))
  (display "log p(2.0):" (.toFixed (observe* d 2.0) 4))
  (density (repeatedly 1000 #(sample* d)) "KDE from 6 points"))</code></pre>
</div>

<div class="fn-entry" id="marginal-dist">
<h3><a href="#marginal-dist"><code>marginal-dist</code></a></h3>
<div class="fn-signature">(marginal-dist method thunk)</div>
<p class="fn-description">Cached marginal distribution from inner inference. <em>method</em> is an inference function (e.g. <code>enumeration-query-fn</code>), <em>thunk</em> is a zero-arg model function. The result is computed once and cached. Supports <code>enumerate*</code>.</p>
<pre><code>;; Wrap inner inference as a reusable distribution
(let [d (marginal-dist enumeration-query-fn
          (fn [] (let [a (flip) b (flip)]
                   (condition (or a b))
                   (list a b))))]
  (display "sample:" (sample* d))
  (display "support:" (enumerate* d))
  (barplot d "P(a,b | a or b)"))</code></pre>
</div>

<h3 id="dist-utilities"><a href="#dist-utilities">Distribution Utilities</a></h3>
<p>Functions for analyzing and comparing distributions.</p>

<div class="fn-entry" id="entropy">
<h3><a href="#entropy"><code>entropy</code></a></h3>
<div class="fn-signature">(entropy dist)</div>
<p class="fn-description">Shannon entropy \(H(p) = -\sum p(x) \ln p(x)\) of a discrete distribution. Distribution must implement <code>IEnumerable</code>. Maximum entropy is \(\ln(n)\) for a uniform distribution over <em>n</em> outcomes.</p>
<pre><code>;; Maximum entropy for uniform, lower for biased
(display "fair coin:" (.toFixed (entropy (bernoulli-dist 0.5)) 4))
(display "biased coin:" (.toFixed (entropy (bernoulli-dist 0.9)) 4))
(display "die (ln 6):" (.toFixed (entropy (uniform-discrete-dist 1 6)) 4))</code></pre>
</div>

<div class="fn-entry" id="kl-divergence">
<h3><a href="#kl-divergence"><code>kl-divergence</code></a></h3>
<div class="fn-signature">(kl-divergence p q)</div>
<p class="fn-description">KL divergence \(D_{KL}(p \| q) = \sum p(x) \ln \frac{p(x)}{q(x)}\) for discrete distributions. Both must implement <code>IEnumerable</code>. Always \(\geq 0\), with equality iff \(p = q\). Not symmetric.</p>
<pre><code>(let [p (bernoulli-dist 0.7)
      q (bernoulli-dist 0.5)]
  (display "KL(p||p):" (.toFixed (kl-divergence p p) 6))
  (display "KL(p||q):" (.toFixed (kl-divergence p q) 4))
  (display "KL(q||p):" (.toFixed (kl-divergence q p) 4)))</code></pre>
</div>

<div class="fn-entry" id="discrete-pred">
<h3><a href="#discrete-pred"><code>discrete?</code> / <code>continuous?</code></a></h3>
<div class="fn-signature">(discrete? dist) (continuous? dist)</div>
<p class="fn-description">Type predicates. <code>discrete?</code> returns true if the distribution implements <code>IEnumerable</code> (has finite support). <code>continuous?</code> returns true if it implements <code>IDistribution</code> but not <code>IEnumerable</code>.</p>
<pre><code>(display "bernoulli discrete?:" (discrete? (bernoulli-dist)))
(display "gaussian discrete?:" (discrete? (gaussian-dist)))
(display "gaussian continuous?:" (continuous? (gaussian-dist)))
(display "poisson continuous?:" (continuous? (poisson-dist 3)))</code></pre>
</div>

<div class="fn-entry" id="dist-pred">
<h3><a href="#dist-pred"><code>dist?</code></a></h3>
<div class="fn-signature">(dist? x)</div>
<p class="fn-description">Returns true if <em>x</em> implements <code>IDistribution</code>. Useful for checking whether a value is a distribution object or a plain value.</p>
<pre><code>(display "dist object:" (dist? (gaussian-dist)))
(display "plain number:" (dist? 42))
(display "nil:" (dist? nil))</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="inference"><a href="#inference">Inference</a></h2>
<p>Inference algorithms condition generative models on observations. The macro forms wrap the body in a thunk automatically.</p>

<div class="fn-entry" id="rejection-query">
<h3><a href="#rejection-query"><code>rejection-query</code></a></h3>
<div class="fn-signature">(rejection-query &amp; body)</div>
<p class="fn-description">Run the body repeatedly until all <code>condition</code> constraints are satisfied, then return the value. Simple but can be slow when the condition is unlikely. Macro over <code>rejection-query-fn</code>.</p>
<pre><code>;; Sample a die roll conditioned on being > 4
(rejection-query
  (let [die (uniform-draw [1 2 3 4 5 6])]
    (condition (> die 4))
    die))</code></pre>
</div>

<div class="fn-entry" id="mh-query">
<h3><a href="#mh-query"><code>mh-query</code></a></h3>
<div class="fn-signature">(mh-query num-samples lag &amp; body)</div>
<p class="fn-description">Metropolis-Hastings inference. Draws <em>num-samples</em> from the posterior using single-site trace-based MH with thinning interval <em>lag</em>. Supports continuous and discrete random choices. Macro over <code>mh-query-fn</code>.</p>
<pre><code>;; Estimate a coin's bias from observations
(let [data [true true true false true]
      samples (mh-query 500 1
                (let [p (beta 1 1)]
                  (doseq [d data] (condition (= d (flip p))))
                  p))]
  (display "estimated bias:" (.toFixed (mean samples) 3))
  (density samples "posterior over p"))</code></pre>
</div>

<div class="fn-entry" id="enumeration-query">
<h3><a href="#enumeration-query"><code>enumeration-query</code></a></h3>
<div class="fn-signature">(enumeration-query &amp; body)</div>
<p class="fn-description">Exact posterior by enumerating all possible executions. Returns <code>[values probabilities]</code>. Only works when all random choices are discrete and finite. Macro over <code>enumeration-query-fn</code>.</p>
<pre><code>;; Exact posterior: P(A, B | A or B)
(barplot
  (enumeration-query
    (let [a (flip) b (flip)]
      (condition (or a b))
      (list a b)))
  "P(a,b | a or b)")</code></pre>
</div>

<div class="fn-entry" id="forward-query">
<h3><a href="#forward-query"><code>forward-query</code></a></h3>
<div class="fn-signature">(forward-query n &amp; body) (forward-query-fn n thunk)</div>
<p class="fn-description">Forward sampling from the prior. Runs the model <em>n</em> times with <code>factor</code>, <code>observe</code>, and <code>condition</code> as no-ops. Returns a vector of <em>n</em> unweighted prior samples. Useful for visualizing the prior distribution before adding observations.</p>
<pre><code>;; Visualize the prior over a latent parameter
(let [samples (forward-query 1000
                (let [mu (gaussian 0 3)]
                  (observe (gaussian-dist mu 1) 2.5)  ; ignored in forward mode
                  mu))]
  (display "prior mean:" (.toFixed (mean samples) 3))
  (density samples "prior over mu (observations ignored)"))</code></pre>
</div>

<div class="fn-entry" id="importance-query">
<h3><a href="#importance-query"><code>importance-query</code></a></h3>
<div class="fn-signature">(importance-query n &amp; body) (importance-query-fn n thunk)</div>
<p class="fn-description">Importance sampling with <em>n</em> weighted samples. Returns <code>(values probs)</code> like <code>enumeration-query</code>. Each sample is weighted by the accumulated <code>factor</code>/<code>observe</code> scores, then normalized. More scalable than enumeration for models with many random choices.</p>
<pre><code>;; Importance sampling over a discrete model
(barplot
  (importance-query 5000
    (let [x (uniform-draw [1 2 3 4 5])]
      (observe (gaussian-dist x 0.5) 3.2)
      x))
  "P(x | obs=3.2) via importance sampling")</code></pre>
</div>

<div class="fn-entry" id="map-query">
<h3><a href="#map-query"><code>map-query</code></a></h3>
<div class="fn-signature">(map-query n lag &amp; body) (map-query-fn n lag thunk)</div>
<p class="fn-description">MAP (maximum a posteriori) inference. Runs MH to collect <em>n</em> scored samples with thinning <em>lag</em>, then returns the single highest-scoring value. Useful when you want the most likely explanation rather than the full posterior.</p>
<pre><code>;; Find the most likely die given an observation
(let [best (map-query 1000 1
             (let [die (uniform-draw [:d4 :d6 :d8 :d12 :d20])
                   sides (get {:d4 4 :d6 6 :d8 8 :d12 12 :d20 20} die)
                   roll (uniform-draw (range 1 (inc sides)))]
               (condition (= roll 7))
               die))]
  (display "MAP die:" best))</code></pre>
</div>

<div class="fn-entry" id="mh-query-scored">
<h3><a href="#mh-query-scored"><code>mh-query-scored</code></a></h3>
<div class="fn-signature">(mh-query-scored n lag &amp; body) (mh-query-scored-fn n lag thunk)</div>
<p class="fn-description">Like <code>mh-query</code> but returns a list of <code>{:value v :score s}</code> maps, where <em>score</em> is the log-probability of each sample. Useful for diagnostics, finding the MAP estimate manually, or weighted post-processing.</p>
<pre><code>;; See values with their log-scores
(let [results (mh-query-scored 200 1
                (let [p (beta 2 2)]
                  (condition (flip p))
                  (condition (flip p))
                  (condition (flip p))
                  (.toFixed p 2)))
      best (apply max-key :score results)]
  (display "best value:" (:value best) "score:" (.toFixed (:score best) 3))
  (hist (map :value results) "posterior samples with scores"))</code></pre>
</div>

<div class="fn-entry" id="infer">
<h3><a href="#infer"><code>infer</code></a></h3>
<div class="fn-signature">(infer opts thunk)</div>
<p class="fn-description">Unified entry point for all inference methods. Dispatches based on <code>:method</code> key in <em>opts</em>. Available methods: <code>:rejection</code>, <code>:mh</code>, <code>:enumeration</code>, <code>:importance</code>, <code>:forward</code>, <code>:mh-scored</code>, <code>:map</code>. Each method accepts its own options (e.g. <code>:samples</code>, <code>:lag</code>, <code>:burn</code>). SMC and particle Gibbs also exist but require CPS-transformed models.</p>
<pre><code>;; Same model, different inference methods
(let [model (fn []
              (let [x (uniform-draw [1 2 3 4 5])]
                (factor (* 0.5 x))
                x))]
  ;; Exact enumeration
  (barplot (infer {:method :enumeration} model)
    "enumeration (exact)")
  ;; MH sampling
  (hist (infer {:method :mh :samples 1000 :lag 1} model)
    "MH (1000 samples)")
  ;; Importance sampling
  (barplot (infer {:method :importance :samples 2000} model)
    "importance (2000 samples)"))</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="conditioning"><a href="#conditioning">Conditioning</a></h2>
<p>Conditioning constrains generative models to match observations.</p>

<div class="fn-entry" id="condition">
<h3><a href="#condition"><code>condition</code></a></h3>
<div class="fn-signature">(condition pred)</div>
<p class="fn-description">Hard constraint: reject the current execution if <em>pred</em> is false. In rejection sampling, throws a rejection sentinel. In MH, sets the score to \(-\infty\).</p>
<pre><code>(hist
  (repeatedly 1000
    #(rejection-query
       (let [x (uniform-draw (range 1 11))]
         (condition (even? x))
         x)))
  "uniform over even numbers 1-10")</code></pre>
</div>

<div class="fn-entry" id="factor">
<h3><a href="#factor"><code>factor</code></a></h3>
<div class="fn-signature">(factor log-weight)</div>
<p class="fn-description">Soft constraint: add <em>log-weight</em> to the execution score. In rejection mode, probabilistically accepts with \(e^{\text{log-weight}}\). In MH, accumulates into the trace score.</p>
<pre><code>;; Soft-condition: prefer larger values
(barplot
  (enumeration-query
    (let [x (uniform-draw [1 2 3 4 5])]
      (factor (* 0.5 x))
      x))
  "soft preference for larger values")</code></pre>
</div>

<div class="fn-entry" id="observe">
<h3><a href="#observe"><code>observe</code></a></h3>
<div class="fn-signature">(observe dist value)</div>
<p class="fn-description">Condition on observing <em>value</em> from distribution <em>dist</em>. Equivalent to <code>(factor (observe* dist value))</code>. The standard way to incorporate data.</p>
<pre><code>;; Infer mean given noisy observations
(let [data [2.1 1.8 2.3 1.9 2.0]
      samples (mh-query 500 1
                (let [mu (gaussian 0 5)]
                  (doseq [d data]
                    (observe (gaussian-dist mu 0.3) d))
                  mu))]
  (display "estimated mean:" (.toFixed (mean samples) 3))
  (density samples "posterior over mu"))</code></pre>
</div>

<div class="fn-entry" id="condition-equal">
<h3><a href="#condition-equal"><code>condition-equal</code></a></h3>
<div class="fn-signature">(condition-equal thunk value)</div>
<p class="fn-description">Soft conditioning via inner enumeration. Enumerates <em>thunk</em> exhaustively, computes \(P(\text{return} = \text{value})\), and adds \(\log P\) as a factor score. Useful for conditioning on the output of an inner generative model without nesting full inference manually.</p>
<pre><code>;; Condition on the output of an inner model
(barplot
  (enumeration-query
    (let [rain (flip 0.3)
          sprinkler (flip (if rain 0.01 0.4))]
      ;; Condition on observing wet grass via inner model
      (condition-equal
        (fn [] (or rain sprinkler))
        true)
      (list :rain rain :sprinkler sprinkler)))
  "P(rain, sprinkler | wet grass)")</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="utilities"><a href="#utilities">Utilities</a></h2>
<p>Helper functions for statistics, memoization, list operations, and stochastic processes.</p>

<h3 id="statistics"><a href="#statistics">Statistics</a></h3>

<div class="fn-entry" id="mean">
<h3><a href="#mean"><code>mean</code></a></h3>
<div class="fn-signature">(mean coll)</div>
<p class="fn-description">Arithmetic mean of a collection of numbers.</p>
<pre><code>(let [samples (repeatedly 1000 #(gaussian 5 2))]
  (display "mean:" (.toFixed (mean samples) 3)))</code></pre>
</div>

<div class="fn-entry" id="variance-fn">
<h3><a href="#variance-fn"><code>variance</code> / <code>sd</code></a></h3>
<div class="fn-signature">(variance coll) (sd coll)</div>
<p class="fn-description"><code>variance</code> computes the population variance \(\frac{1}{n}\sum(x_i - \bar{x})^2\). <code>sd</code> returns the standard deviation (square root of variance).</p>
<pre><code>(let [samples (repeatedly 1000 #(gaussian 0 3))]
  (display "variance:" (.toFixed (variance samples) 3))
  (display "sd:" (.toFixed (sd samples) 3)))</code></pre>
</div>

<div class="fn-entry" id="sum-prod">
<h3><a href="#sum-prod"><code>sum</code> / <code>prod</code></a></h3>
<div class="fn-signature">(sum coll) (prod coll)</div>
<p class="fn-description"><code>sum</code> computes \(\sum x_i\). <code>prod</code> computes \(\prod x_i\).</p>
<pre><code>(display "sum 1..5:" (sum [1 2 3 4 5]))
(display "prod 1..5:" (prod [1 2 3 4 5]))</code></pre>
</div>

<div class="fn-entry" id="mode">
<h3><a href="#mode"><code>mode</code></a></h3>
<div class="fn-signature">(mode coll)</div>
<p class="fn-description">Most frequent value in a collection. If tied, returns one of the modes.</p>
<pre><code>(display "mode:" (mode [1 2 2 3 3 3 4]))
(display "mode:" (mode ["cat" "dog" "cat" "cat" "dog"]))</code></pre>
</div>

<div class="fn-entry" id="weighted-mean">
<h3><a href="#weighted-mean"><code>weighted-mean</code></a></h3>
<div class="fn-signature">(weighted-mean values weights)</div>
<p class="fn-description">Weighted average \(\frac{\sum w_i x_i}{\sum w_i}\). Useful for computing expectations from importance samples.</p>
<pre><code>(display "weighted:" (.toFixed (weighted-mean [1 2 3] [1 2 7]) 3))
(display "uniform:" (.toFixed (weighted-mean [1 2 3] [1 1 1]) 3))</code></pre>
</div>

<div class="fn-entry" id="weighted-variance">
<h3><a href="#weighted-variance"><code>weighted-variance</code></a></h3>
<div class="fn-signature">(weighted-variance values weights)</div>
<p class="fn-description">Weighted population variance \(\frac{\sum w_i (x_i - \mu_w)^2}{\sum w_i}\).</p>
<pre><code>(display "weighted var:" (.toFixed (weighted-variance [1 2 3 4 5] [1 1 1 1 1]) 3))
(display "compare var:" (.toFixed (variance [1 2 3 4 5]) 3))</code></pre>
</div>

<div class="fn-entry" id="expectation">
<h3><a href="#expectation"><code>expectation</code></a></h3>
<div class="fn-signature">(expectation samples) (expectation samples f)</div>
<p class="fn-description">Expected value. With one argument, computes \(E[X]\) (same as <code>mean</code>). With a function, computes \(E[f(X)]\).</p>
<pre><code>(let [samples (repeatedly 1000 #(gaussian 0 1))]
  (display "E[X]:" (.toFixed (expectation samples) 3))
  (display "E[X^2]:" (.toFixed (expectation samples #(* % %)) 3)))</code></pre>
</div>

<div class="fn-entry" id="empirical-distribution">
<h3><a href="#empirical-distribution"><code>empirical-distribution</code></a></h3>
<div class="fn-signature">(empirical-distribution samples)</div>
<p class="fn-description">Build a frequency table from samples, normalized to probabilities. Returns a map <code>{value probability ...}</code>.</p>
<pre><code>(let [samples (repeatedly 1000 #(uniform-draw ["a" "b" "c"]))
      ed (empirical-distribution samples)]
  (display "P(a):" (.toFixed (get ed "a") 3))
  (display "P(b):" (.toFixed (get ed "b") 3))
  (display "P(c):" (.toFixed (get ed "c") 3)))</code></pre>
</div>

<div class="fn-entry" id="softmax">
<h3><a href="#softmax"><code>softmax</code></a></h3>
<div class="fn-signature">(softmax utilities) (softmax utilities beta)</div>
<p class="fn-description">Softmax (Luce choice rule / Boltzmann distribution). Converts utilities to probabilities: \(P(i) = \frac{e^{\beta V_i}}{\sum_j e^{\beta V_j}}\). Default \(\beta = 1\).</p>
<pre><code>(display "softmax [1 2 3]:" (mapv #(.toFixed % 3) (softmax [1 2 3])))
(display "beta=0.1 (flat):" (mapv #(.toFixed % 3) (softmax [1 2 3] 0.1)))
(display "beta=10 (peaked):" (mapv #(.toFixed % 3) (softmax [1 2 3] 10)))</code></pre>
</div>

<h3 id="memoization"><a href="#memoization">Memoization</a></h3>

<div class="fn-entry" id="mem">
<h3><a href="#mem"><code>mem</code></a></h3>
<div class="fn-signature">(mem f)</div>
<p class="fn-description">Stochastic memoization. Wraps <em>f</em> so that repeated calls with the same arguments return the same (random) value. Trace-aware: memoized values participate in MH proposals and roll back on rejection.</p>
<pre><code>;; Each person gets a persistent random eye color
(let [eye-color (mem (fn [person] (uniform-draw ["blue" "brown" "green"])))]
  (display "alice:" (eye-color "alice"))
  (display "alice again:" (eye-color "alice"))
  (display "bob:" (eye-color "bob")))</code></pre>
</div>

<div class="fn-entry" id="cache">
<h3><a href="#cache"><code>cache</code></a></h3>
<div class="fn-signature">(cache f) (cache f max-size)</div>
<p class="fn-description">LRU-bounded deterministic memoization. Default <em>max-size</em> is 1000. Unlike <code>mem</code>, not trace-aware &mdash; suitable for caching pure computations.</p>
<pre><code>(let [slow-fn (cache (fn [x] (display "computing for" x) (* x x)))]
  (display "first call:" (slow-fn 5))
  (display "cached call:" (slow-fn 5))
  (display "new arg:" (slow-fn 6)))</code></pre>
</div>

<div class="fn-entry" id="DPmem">
<h3><a href="#DPmem"><code>DPmem</code></a></h3>
<div class="fn-signature">(DPmem alpha f)</div>
<p class="fn-description">Dirichlet Process memoization. Uses a Chinese Restaurant Process with concentration <em>alpha</em> to decide whether to reuse a previous result or generate a new one by calling <em>f</em>. Useful for non-parametric clustering.</p>
<pre><code>;; DP-memoized color generator: creates clusters of reuse
(let [get-color (DPmem 1.0 (fn [category] (uniform-draw ["red" "blue" "green" "yellow"])))]
  (hist (repeatedly 20 #(get-color "fruit")) "DP-memoized colors"))</code></pre>
</div>

<h3 id="list-primitives"><a href="#list-primitives">List Primitives</a></h3>

<div class="fn-entry" id="pair">
<h3><a href="#pair"><code>pair</code></a></h3>
<div class="fn-signature">(pair a b)</div>
<p class="fn-description">Cons cell constructor. If <em>b</em> is a list/vector/nil, returns a list with <em>a</em> prepended. Otherwise creates a Pair record (dotted pair).</p>
<pre><code>(display "pair to list:" (pair 1 [2 3]))
(display "dotted pair:" (pair "key" "value"))
(display "nested:" (pair 1 (pair 2 (pair 3 '()))))</code></pre>
</div>

<div class="fn-entry" id="car-cdr">
<h3><a href="#car-cdr"><code>car</code> / <code>cdr</code></a></h3>
<div class="fn-signature">(car x) (cdr x)</div>
<p class="fn-description"><code>car</code> returns the first element; <code>cdr</code> returns the rest. Work on lists, vectors, and Pair records.</p>
<pre><code>(let [p (pair "hello" "world")]
  (display "car:" (car p))
  (display "cdr:" (cdr p)))
(let [lst (list 1 2 3)]
  (display "car:" (car lst))
  (display "cdr:" (cdr lst)))</code></pre>
</div>

<div class="fn-entry" id="repeat-fn">
<h3><a href="#repeat-fn"><code>repeat-fn</code></a></h3>
<div class="fn-signature">(repeat-fn n f)</div>
<p class="fn-description">Call <em>f</em> (a zero-argument function) <em>n</em> times. Returns a lazy sequence of results. Equivalent to <code>(repeatedly n f)</code>.</p>
<pre><code>(display "5 coin flips:" (repeat-fn 5 flip))
(display "3 die rolls:" (repeat-fn 3 #(random-integer 6)))</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="math"><a href="#math">Math</a></h2>
<p>Special mathematical functions. Pure ClojureScript, zero dependencies.</p>

<div class="fn-entry" id="log-gamma-fn">
<h3><a href="#log-gamma-fn"><code>log-gamma-fn</code></a></h3>
<div class="fn-signature">(log-gamma-fn z)</div>
<p class="fn-description">Log of the Gamma function, \(\ln\Gamma(z)\). Uses the Lanczos approximation with ~15 digit accuracy.</p>
<pre><code>;; ln(Gamma(5)) = ln(4!) = ln(24)
(display "log-gamma-fn(5):" (.toFixed (log-gamma-fn 5) 6))
(display "ln(24):" (.toFixed (js/Math.log 24) 6))
;; Stirling check: ln(Gamma(100))
(display "log-gamma-fn(100):" (.toFixed (log-gamma-fn 100) 4))</code></pre>
</div>

<div class="fn-entry" id="log-beta-fn">
<h3><a href="#log-beta-fn"><code>log-beta-fn</code></a></h3>
<div class="fn-signature">(log-beta-fn a b)</div>
<p class="fn-description">Log of the Beta function: \(\ln B(a,b) = \ln\Gamma(a) + \ln\Gamma(b) - \ln\Gamma(a+b)\).</p>
<pre><code>;; B(1,1) = 1, so ln B(1,1) = 0
(display "log-beta-fn(1,1):" (.toFixed (log-beta-fn 1 1) 6))
;; B(2,3) = 1/12
(display "log-beta-fn(2,3):" (.toFixed (log-beta-fn 2 3) 6))
(display "ln(1/12):" (.toFixed (js/Math.log (/ 1 12)) 6))</code></pre>
</div>

<div class="fn-entry" id="log-fact">
<h3><a href="#log-fact"><code>log-fact</code></a></h3>
<div class="fn-signature">(log-fact n)</div>
<p class="fn-description">Log-factorial: \(\ln(n!) = \ln\Gamma(n+1)\). Useful for computing binomial coefficients without overflow.</p>
<pre><code>(display "ln(5!):" (.toFixed (log-fact 5) 6))
(display "ln(120):" (.toFixed (js/Math.log 120) 6))
;; Compute log(100 choose 50) = log(100!) - log(50!) - log(50!)
(display "ln(C(100,50)):" (.toFixed (- (log-fact 100) (log-fact 50) (log-fact 50)) 4))</code></pre>
</div>

<div class="fn-entry" id="log-sum-exp">
<h3><a href="#log-sum-exp"><code>log-sum-exp</code></a></h3>
<div class="fn-signature">(log-sum-exp a b) (log-sum-exp xs)</div>
<p class="fn-description">Numerically stable \(\ln(\sum_i e^{x_i})\). Two-argument form: \(\ln(e^a + e^b)\). One-argument form: takes a collection. Essential for working with log-probabilities.</p>
<pre><code>;; log(exp(-1000) + exp(-1001)) — naive version would underflow
(display "log-sum-exp:" (.toFixed (log-sum-exp -1000 -1001) 4))
;; Collection form
(display "collection:" (.toFixed (log-sum-exp [-100 -101 -102]) 4))</code></pre>
</div>

<div class="fn-entry" id="digamma">
<h3><a href="#digamma"><code>digamma</code></a></h3>
<div class="fn-signature">(digamma x)</div>
<p class="fn-description">Digamma function \(\psi(x) = \frac{d}{dx}\ln\Gamma(x)\). Used in gradient computations for Beta, Dirichlet, and Gamma distributions.</p>
<pre><code>;; psi(1) = -gamma (Euler-Mascheroni constant)
(display "digamma(1):" (.toFixed (digamma 1) 6))
(display "~= -0.5772:" (.toFixed -0.5772156649 6))
;; psi(n) = H_{n-1} - gamma for positive integers
(display "digamma(5):" (.toFixed (digamma 5) 6))</code></pre>
</div>

<div class="fn-entry" id="erf">
<h3><a href="#erf"><code>erf</code></a></h3>
<div class="fn-signature">(erf x)</div>
<p class="fn-description">The error function, \(\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} dt\). Abramowitz &amp; Stegun approximation with max error ~1.5&times;10<sup>-7</sup>.</p>
<pre><code>;; erf(0) = 0, erf(inf) -> 1
(display "erf(0):" (erf 0))
(display "erf(1):" (.toFixed (erf 1) 6))
(display "erf(2):" (.toFixed (erf 2) 6))
;; P(|X| < 1) for standard normal = erf(1/sqrt(2))
(display "P(|Z|<1):" (.toFixed (erf (/ 1 (js/Math.sqrt 2))) 4))</code></pre>
</div>

<!-- ============================================================ -->
<h2 id="visualization"><a href="#visualization">Visualization</a></h2>
<p>In-browser visualization functions for probability distributions, data, and inference results. All charts are rendered as inline SVG.</p>

<div class="fn-entry" id="display-viz">
<h3><a href="#display-viz"><code>display</code></a></h3>
<div class="fn-signature">(display &amp; args)</div>
<p class="fn-description">Print text to the output area. Joins arguments with spaces. The primary way to show non-graphical results.</p>
<pre><code>(display "hello" "world")
(display "pi ≈" (.toFixed js/Math.PI 6))
(display "random:" (.toFixed (gaussian 0 1) 4))</code></pre>
</div>

<div class="fn-entry" id="hist">
<h3><a href="#hist"><code>hist</code></a></h3>
<div class="fn-signature">(hist data label)</div>
<p class="fn-description">Frequency histogram. Shows the count of each distinct value as a bar. Best for discrete or categorical data.</p>
<pre><code>(hist (repeatedly 1000 #(random-integer 6)) "die rolls")
(hist (repeatedly 500 #(if (flip) "heads" "tails")) "coin flips")</code></pre>
</div>

<div class="fn-entry" id="density-viz">
<h3><a href="#density-viz"><code>density</code></a></h3>
<div class="fn-signature">(density data label)</div>
<p class="fn-description">Kernel density estimate plot. Smooths continuous samples into an estimated PDF curve. Bandwidth is chosen automatically via Silverman's rule.</p>
<pre><code>(density (repeatedly 1000 #(gaussian 0 1)) "standard normal")
(density (repeatedly 1000 #(beta 2 5)) "Beta(2, 5)")</code></pre>
</div>

<div class="fn-entry" id="barplot">
<h3><a href="#barplot"><code>barplot</code></a></h3>
<div class="fn-signature">(barplot [values probs] label)</div>
<p class="fn-description">Probability bar chart for enumeration results. Takes <code>[values probs]</code> as returned by <code>enumeration-query</code>. Shows each value with its exact probability labeled above the bar.</p>
<pre><code>(barplot
  (enumeration-query
    (let [x (uniform-draw [1 2 3 4 5])]
      (condition (odd? x))
      x))
  "P(x | x is odd)")</code></pre>
</div>

<div class="fn-entry" id="scatter-viz">
<h3><a href="#scatter-viz"><code>scatter</code></a></h3>
<div class="fn-signature">(scatter data label)</div>
<p class="fn-description">Scatter plot from <code>[x y]</code> pairs. Includes axis labels and grid. Points are rendered as semi-transparent circles.</p>
<pre><code>(scatter
  (repeatedly 200 #(let [x (gaussian 0 1)] [x (+ (* 2 x) (gaussian 0 0.5))]))
  "y = 2x + noise")</code></pre>
</div>

<div class="fn-entry" id="lineplot-viz">
<h3><a href="#lineplot-viz"><code>lineplot</code></a></h3>
<div class="fn-signature">(lineplot data label)</div>
<p class="fn-description">Line chart. Data is a sequence of <code>[x y]</code> pairs (sorted by x) or a vector of series maps <code>{:data [[x y]...] :label "name"}</code> for multi-series. Includes a legend for multiple series.</p>
<pre><code>;; Single series: sin(x)
(lineplot (for [x (range 0 6.3 0.1)] [x (js/Math.sin x)]) "sin(x)")
;; Multi-series
(lineplot [{:data (for [x (range 0 6.3 0.1)] [x (js/Math.sin x)]) :label "sin"}
           {:data (for [x (range 0 6.3 0.1)] [x (js/Math.cos x)]) :label "cos"}]
  "trig functions")</code></pre>
</div>

<div class="fn-entry" id="table-viz">
<h3><a href="#table-viz"><code>table</code></a></h3>
<div class="fn-signature">(table data label)</div>
<p class="fn-description">Render data as an HTML table. <em>data</em> is a sequence of rows, where each row is a sequence of cell values.</p>
<pre><code>(table [["Name" "P(heads)"]
        ["fair" 0.5]
        ["biased" 0.8]
        ["trick" 1.0]]
  "coin types")</code></pre>
</div>

<div class="fn-entry" id="heatmap-viz">
<h3><a href="#heatmap-viz"><code>heatmap</code></a></h3>
<div class="fn-signature">(heatmap data label)</div>
<p class="fn-description">Color-mapped grid. <em>data</em> is either a matrix (sequence of rows) or a sequence of <code>[x y value]</code> triples. Includes axis labels and a color scale legend.</p>
<pre><code>;; Matrix form: 2D Gaussian bump
(heatmap
  (for [i (range 5)]
    (for [j (range 5)]
      (js/Math.exp (- 0 (+ (* (- i 2) (- i 2)) (* (- j 2) (- j 2)))))))
  "Gaussian bump")</code></pre>
</div>

<div class="fn-entry" id="marginals-viz">
<h3><a href="#marginals-viz"><code>marginals</code></a></h3>
<div class="fn-signature">(marginals data label)</div>
<p class="fn-description">Plot marginal distributions for multi-dimensional samples. Accepts a sequence of maps (one plot per key) or a sequence of vectors (one plot per index). Automatically chooses <code>density</code> for numeric dimensions and <code>hist</code> for categorical.</p>
<pre><code>;; Sequence of maps — one density per key
(marginals
  (repeatedly 500 #(hash-map :mu (gaussian 0 1) :sigma (js/Math.abs (gaussian 0 1))))
  "parameters")</code></pre>
</div>

<div class="fn-entry" id="auto-viz">
<h3><a href="#auto-viz"><code>auto</code></a></h3>
<div class="fn-signature">(auto data label)</div>
<p class="fn-description">Auto-detect the best visualization for the data. Dispatches to <code>barplot</code> for <code>[values probs]</code> pairs, <code>scatter</code>/<code>lineplot</code> for numeric <code>[x y]</code> data, <code>marginals</code> for maps, <code>density</code> for many distinct numbers, or <code>hist</code> for categorical data.</p>
<pre><code>;; Auto picks density for continuous data
(auto (repeatedly 1000 #(gaussian 0 1)) "auto: continuous")
;; Auto picks barplot for enumeration result
(auto (enumeration-query (let [x (flip)] (condition x) x)) "auto: enumeration")</code></pre>
</div>

</div><!-- #content -->
</div><!-- #page-wrapper -->

<!-- Interactive runner: loads prob-cljs via fetch + eval_string -->
<script>
var _scittleReady = false;
var _scittleLoading = null;

function ensureScittleImports() {
  if (_scittleReady) return Promise.resolve();
  if (_scittleLoading) return _scittleLoading;

  var files = [
    '../prob/math.cljs',
    '../prob/erp.cljs',
    '../prob/dist.cljs',
    '../prob/cps_transform.cljc',
    '../prob/cps.cljs',
    '../prob/inference.cljs',
    '../prob/builtins.cljs',
    '../prob/core.cljs',
    'viz.cljs'
  ];

  _scittleLoading = Promise.all(files.map(function(f) {
    return fetch(f).then(function(r) {
      if (!r.ok) throw new Error('Failed to load ' + f + ': ' + r.status);
      return r.text();
    });
  })).then(function(sources) {
    sources.forEach(function(src) { scittle.core.eval_string(src); });

    scittle.core.eval_string(
      "(ns prob.macros)" +
      "(defmacro rejection-query [& body] `(prob.core/rejection-query-fn (fn [] ~@body)))" +
      "(defmacro mh-query [n lag & body] `(prob.core/mh-query-fn ~n ~lag (fn [] ~@body)))" +
      "(defmacro enumeration-query [& body] `(prob.core/enumeration-query-fn (fn [] ~@body)))" +
      "(defmacro forward-query [n & body] `(prob.core/forward-query-fn ~n (fn [] ~@body)))" +
      "(defmacro importance-query [n & body] `(prob.core/importance-query-fn ~n (fn [] ~@body)))" +
      "(defmacro map-query [n lag & body] `(prob.core/map-query-fn ~n ~lag (fn [] ~@body)))" +
      "(defmacro mh-query-scored [n lag & body] `(prob.core/mh-query-scored-fn ~n ~lag (fn [] ~@body)))"
    );

    scittle.core.eval_string(
      "(require '[prob.core :refer [flip gaussian uniform uniform-draw random-integer multinomial" +
      "                              sample-discrete beta gamma dirichlet exponential" +
      "                              binomial poisson categorical rand set-seed!" +
      "                              condition factor observe rejection-query-fn mh-query-fn" +
      "                              enumeration-query-fn forward-query-fn importance-query-fn" +
      "                              map-query-fn mh-query-scored-fn infer condition-equal" +
      "                              mem mean variance sd sum prod mode" +
      "                              weighted-mean weighted-variance expectation" +
      "                              empirical-distribution softmax repeat-fn" +
      "                              sample* observe* dist? enumerate*" +
      "                              DPmem cache log-gamma-fn log-beta-fn log-fact" +
      "                              log-sum-exp erf digamma]])" +
      "(require '[prob.dist :refer [observe* sample* dist? enumerate*" +
      "                              gaussian-dist bernoulli-dist uniform-dist beta-dist gamma-dist" +
      "                              exponential-dist dirichlet-dist uniform-draw-dist" +
      "                              random-integer-dist multinomial-dist sample-discrete-dist" +
      "                              binomial-dist poisson-dist categorical-dist" +
      "                              delta-dist cauchy-dist laplace-dist lognormal-dist" +
      "                              student-t-dist mixture-dist kde-dist marginal-dist" +
      "                              uniform-discrete-dist chi-squared-dist logit-normal-dist" +
      "                              entropy kl-divergence discrete? continuous?]])" +
      "(require '[prob.builtins :refer [expt pair car cdr pair?]])" +
      "(require '[prob.macros :refer [rejection-query mh-query enumeration-query" +
      "                                  forward-query importance-query map-query mh-query-scored]])" +
      "(require '[prob.viz :refer [hist density scatter barplot display lineplot table heatmap marginals auto]])"
    );

    _scittleReady = true;
  });

  return _scittleLoading;
}

function runCode(code, output) {
  output.innerHTML = '';
  window.__currentOutput = output;
  window.__appendToOutput = function(el) { window.__currentOutput.appendChild(el); };
  window.__appendTextToOutput = function(text) {
    var span = document.createElement('span');
    span.textContent = text + '\n';
    window.__currentOutput.appendChild(span);
  };
  ensureScittleImports().then(function() {
    window.__currentOutput = output;
    try {
      var result = scittle.core.eval_string(code);
      if (result != null) {
        var span = document.createElement('span');
        span.textContent = '' + result;
        output.appendChild(span);
      }
    } catch(e) {
      var span = document.createElement('span');
      span.className = 'error';
      span.textContent = 'Error: ' + e.message;
      output.appendChild(span);
    }
  }).catch(function(e) {
    var span = document.createElement('span');
    span.className = 'error';
    span.textContent = 'Load error: ' + e.message;
    output.appendChild(span);
  });
}

document.querySelectorAll('#content pre').forEach(function(pre) {
  var codeEl = pre.querySelector('code');
  if (!codeEl) return;
  var code = codeEl.textContent.trim();

  var container = document.createElement('div');
  container.className = 'code-example';

  var editorDiv = document.createElement('div');

  var toolbar = document.createElement('div');
  toolbar.className = 'toolbar';

  var btn = document.createElement('button');
  btn.textContent = 'Run';

  var output = document.createElement('div');
  output.className = 'output';

  toolbar.appendChild(btn);
  container.appendChild(editorDiv);
  container.appendChild(toolbar);
  container.appendChild(output);
  pre.replaceWith(container);

  var editor = ProbEditor.createEditor(editorDiv, code, {
    onEval: function(code) { runCode(code, output); }
  });

  btn.addEventListener('click', function() {
    runCode(editor.getCode(), output);
  });
});

// Sidebar highlight on scroll
(function() {
  var links = document.querySelectorAll('#sidebar a[href^="#"]');
  var sections = [];
  links.forEach(function(a) {
    var id = a.getAttribute('href').slice(1);
    var el = document.getElementById(id);
    if (el) sections.push({ el: el, a: a, li: a.parentElement });
  });
  function update() {
    var scrollY = window.scrollY + 80;
    var current = null;
    sections.forEach(function(s) {
      if (s.el.offsetTop <= scrollY) current = s;
    });
    sections.forEach(function(s) { s.li.classList.remove('active'); });
    if (current) current.li.classList.add('active');
  }
  window.addEventListener('scroll', update, { passive: true });
  update();
})();
</script>
</body>
</html>
